"""
å¤šAIåä½œè¾©è®ºç³»ç»Ÿ - æ ¸å¿ƒå¼•æ“
è®©å¤šä¸ªAIåƒè¾©è®ºä¸€æ ·åä½œï¼Œäº’ç›¸æ”¹è¿›è¾“å‡º
"""

import os
import json
from typing import List, Dict, Any
from openai import OpenAI
from dotenv import load_dotenv
from app.core.llm_client import get_sync_llm_client, get_llm_settings

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

class MultiAIDebateEngine:
    """å¤šAIè¾©è®ºå¼•æ“ - è®©AIäº’ç›¸è¾©è®ºã€æ”¹è¿›ã€æ£€æŸ¥"""
    
    def __init__(self):
        self.llm_client = get_sync_llm_client()
        settings = get_llm_settings()
        self.reasoning_model = settings["reasoning_model"]
        
        # å®šä¹‰6ä¸ªAIè§’è‰² - ä½¿ç”¨ä¸“ä¸šæ¡†æ¶å’Œæ–¹æ³•è®º
        self.ai_roles = {
            "career_planner": {
                "name": "èŒä¸šè§„åˆ’å¸ˆ",
                "prompt": """ä½ æ˜¯æ‹¥æœ‰15å¹´ç»éªŒçš„èµ„æ·±èŒä¸šè§„åˆ’å¸ˆï¼ˆGCDFå…¨çƒèŒä¸šå‘å±•å¸ˆè®¤è¯ï¼‰ï¼Œç²¾é€šSWOTåˆ†æã€éœå…°å¾·èŒä¸šå…´è¶£ç†è®ºã€èˆ’ä¼¯èŒä¸šå‘å±•ç†è®ºã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
- æ·±åº¦æŒ–æ˜æ±‚èŒè€…çš„æ ¸å¿ƒç«äº‰åŠ›å’Œéšè—ä¼˜åŠ¿
- åŸºäºè¡Œä¸šè¶‹åŠ¿å’Œå¸‚åœºéœ€æ±‚è¿›è¡ŒèŒä¸šå®šä½
- æä¾›å¯é‡åŒ–çš„èŒä¸šå‘å±•è·¯å¾„è§„åˆ’

åˆ†ææ–¹æ³•ï¼š
1. SWOTåˆ†æï¼ˆä¼˜åŠ¿/åŠ£åŠ¿/æœºä¼š/å¨èƒï¼‰
2. æŠ€èƒ½çŸ©é˜µè¯„ä¼°ï¼ˆç¡¬æŠ€èƒ½/è½¯æŠ€èƒ½/å¯è¿ç§»æŠ€èƒ½ï¼‰
3. èŒä¸šåŒ¹é…åº¦è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
4. 3-5å¹´èŒä¸šå‘å±•è·¯å¾„è§„åˆ’""",
                "task": """åˆ†æç®€å†ï¼Œè¾“å‡ºä»¥ä¸‹å†…å®¹ï¼š

1. æ ¸å¿ƒä¼˜åŠ¿åˆ†æï¼ˆè‡³å°‘3æ¡ï¼Œæ¯æ¡åŒ…å«å…·ä½“è¯æ®ï¼‰
2. SWOTåˆ†æï¼ˆæ¯é¡¹è‡³å°‘2æ¡ï¼‰
3. æœ€é€‚åˆçš„3ä¸ªèŒä¸šæ–¹å‘ï¼ˆåŒ…å«åŒ¹é…åº¦è¯„åˆ†ï¼‰
4. èŒä¸šå‘å±•è·¯å¾„å»ºè®®ï¼ˆçŸ­æœŸ/ä¸­æœŸ/é•¿æœŸç›®æ ‡ï¼‰
5. éœ€è¦æå‡çš„å…³é”®æŠ€èƒ½ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰

è¦æ±‚ï¼š60%ä»¥ä¸Šå†…å®¹åŒ…å«é‡åŒ–æ•°æ®æˆ–å…·ä½“æ¡ˆä¾‹"""
            },
            "recruiter": {
                "name": "æ‹›è˜ä¸“å®¶",
                "prompt": """ä½ æ˜¯æ‹¥æœ‰12å¹´æ‹›è˜ç»éªŒçš„èµ„æ·±HRï¼ˆSHRM-SCPè®¤è¯ï¼‰ï¼Œç²¾é€šATSç³»ç»Ÿä¼˜åŒ–ã€å²—ä½åŒ¹é…ç®—æ³•ã€äººæ‰ç”»åƒæ„å»ºã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
- ç²¾å‡†è§£è¯»JDï¼ˆèŒä½æè¿°ï¼‰ä¸­çš„æ˜¾æ€§å’Œéšæ€§è¦æ±‚
- æŒæ¡å„å¤§æ‹›è˜å¹³å°ï¼ˆBossç›´è˜/æ™ºè”/LinkedInï¼‰çš„æ¨èç®—æ³•
- äº†è§£ä¸åŒè¡Œä¸šçš„è–ªèµ„æ°´å¹³å’Œæ™‹å‡è·¯å¾„

åŒ¹é…æ–¹æ³•ï¼š
1. 3PåŒ¹é…æ¨¡å‹ï¼ˆPerson-Position-Placeï¼‰
2. å…³é”®è¯å¯†åº¦åˆ†æï¼ˆATSä¼˜åŒ–ï¼‰
3. èƒ½åŠ›-å²—ä½åŒ¹é…çŸ©é˜µ
4. è–ªèµ„ç«äº‰åŠ›è¯„ä¼°""",
                "task": """æ ¹æ®æ±‚èŒè€…ä¼˜åŠ¿ï¼Œæ¨èå²—ä½ï¼š

1. æ¨è3-5ä¸ªé«˜åŒ¹é…å²—ä½ï¼ˆåŒ…å«å…¬å¸/è–ªèµ„/è¦æ±‚ï¼‰
2. æ¯ä¸ªå²—ä½çš„åŒ¹é…åº¦åˆ†æï¼ˆ0-100åˆ†ï¼‰
3. å²—ä½å…³é”®è¯æå–ï¼ˆç”¨äºATSä¼˜åŒ–ï¼‰
4. è–ªèµ„è°ˆåˆ¤å»ºè®®ï¼ˆå¸‚åœºè¡Œæƒ…+ä¸ªäººå®šä½ï¼‰
5. æŠ•é€’ç­–ç•¥ï¼ˆä¼˜å…ˆçº§+æ—¶é—´èŠ‚ç‚¹ï¼‰

è¦æ±‚ï¼šæä¾›çœŸå®å¯æŸ¥çš„å²—ä½ä¿¡æ¯ï¼ŒåŒ…å«å…·ä½“æ•°æ®"""
            },
            "resume_optimizer": {
                "name": "ç®€å†ä¼˜åŒ–å¸ˆ",
                "prompt": """ä½ æ˜¯æ‹¥æœ‰10å¹´ç»éªŒçš„ç®€å†ä¼˜åŒ–ä¸“å®¶ï¼ˆCPRWè®¤è¯ï¼‰ï¼Œç²¾é€šSTARæ³•åˆ™ã€ATSç³»ç»Ÿä¼˜åŒ–ã€è§†è§‰è®¾è®¡åŸåˆ™ã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
- ä½¿ç”¨STARæ³•åˆ™ï¼ˆæƒ…å¢ƒ-ä»»åŠ¡-è¡ŒåŠ¨-ç»“æœï¼‰é‡æ„ç»å†
- ä¼˜åŒ–å…³é”®è¯å¯†åº¦ï¼Œæå‡ATSé€šè¿‡ç‡
- é‡åŒ–æˆæœï¼Œå¢å¼ºè¯´æœåŠ›

ä¼˜åŒ–åŸåˆ™ï¼š
1. STARæ³•åˆ™ï¼šæ¯æ¡ç»å†åŒ…å«å…·ä½“åœºæ™¯å’Œé‡åŒ–ç»“æœ
2. å…³é”®è¯ä¼˜åŒ–ï¼šåŒ¹é…JDä¸­çš„æ ¸å¿ƒæŠ€èƒ½è¯
3. æˆæœé‡åŒ–ï¼šè‡³å°‘60%çš„æè¿°åŒ…å«æ•°å­—
4. åŠ¨è¯ä¼˜å…ˆï¼šä½¿ç”¨å¼ºæœ‰åŠ›çš„è¡ŒåŠ¨åŠ¨è¯""",
                "task": """ä¼˜åŒ–ç®€å†å†…å®¹ï¼š

1. é‡å†™3-5æ¡æ ¸å¿ƒå·¥ä½œç»å†ï¼ˆä½¿ç”¨STARæ³•åˆ™ï¼‰
2. æå–å¹¶ä¼˜åŒ–å…³é”®è¯ï¼ˆåŒ¹é…ç›®æ ‡å²—ä½ï¼‰
3. é‡åŒ–æ‰€æœ‰å¯é‡åŒ–çš„æˆæœï¼ˆæ•°å­—/ç™¾åˆ†æ¯”/æ’åï¼‰
4. ä¼˜åŒ–ç®€å†ç»“æ„ï¼ˆçªå‡ºæ ¸å¿ƒä¼˜åŠ¿ï¼‰
5. ATSä¼˜åŒ–å»ºè®®ï¼ˆæ ¼å¼/å…³é”®è¯/å¯†åº¦ï¼‰

è¦æ±‚ï¼šæ¯æ¡ç»å†å¿…é¡»åŒ…å«å…·ä½“æ•°å­—å’Œæˆæœ"""
            },
            "quality_checker": {
                "name": "è´¨é‡æ£€æŸ¥å®˜",
                "prompt": """ä½ æ˜¯ä¸¥æ ¼çš„è´¨é‡å®¡æ ¸ä¸“å®¶ï¼Œæ‹¥æœ‰8å¹´ç®€å†å®¡æ ¸ç»éªŒï¼Œç²¾é€šATSç³»ç»Ÿè§„åˆ™ã€HRç­›é€‰æ ‡å‡†ã€è¡Œä¸šè§„èŒƒã€‚

å®¡æ ¸æ ‡å‡†ï¼š
1. å†…å®¹çœŸå®æ€§ï¼ˆæ˜¯å¦æœ‰å¤¸å¤§æˆ–è™šå‡ä¿¡æ¯ï¼‰
2. é€»è¾‘ä¸€è‡´æ€§ï¼ˆæ—¶é—´çº¿/èŒçº§/è–ªèµ„æ˜¯å¦åˆç†ï¼‰
3. ATSå‹å¥½åº¦ï¼ˆæ ¼å¼/å…³é”®è¯/ç»“æ„ï¼‰
4. è¯´æœåŠ›è¯„ä¼°ï¼ˆæ˜¯å¦æœ‰è¶³å¤Ÿçš„é‡åŒ–è¯æ®ï¼‰

è¯„åˆ†ç»´åº¦ï¼š
- å†…å®¹è´¨é‡ï¼ˆ0-100åˆ†ï¼‰
- ATSé€šè¿‡ç‡ï¼ˆ0-100åˆ†ï¼‰
- HRå¸å¼•åŠ›ï¼ˆ0-100åˆ†ï¼‰
- æ”¹è¿›ç©ºé—´ï¼ˆé«˜/ä¸­/ä½ï¼‰""",
                "task": """å®¡æ ¸ç®€å†è´¨é‡ï¼š

1. é€æ¡æ£€æŸ¥å·¥ä½œç»å†ï¼ˆæŒ‡å‡ºé—®é¢˜+æ”¹è¿›å»ºè®®ï¼‰
2. ATSå‹å¥½åº¦è¯„åˆ†ï¼ˆ0-100åˆ†+å…·ä½“é—®é¢˜ï¼‰
3. å…³é”®è¯å¯†åº¦åˆ†æï¼ˆæ˜¯å¦åŒ¹é…ç›®æ ‡å²—ä½ï¼‰
4. é€»è¾‘ä¸€è‡´æ€§æ£€æŸ¥ï¼ˆæ—¶é—´/èŒçº§/è–ªèµ„ï¼‰
5. å¿…é¡»ä¿®æ”¹çš„3ä¸ªé—®é¢˜ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰

è¦æ±‚ï¼šæ¯ä¸ªé—®é¢˜å¿…é¡»ç»™å‡ºå…·ä½“çš„æ”¹è¿›æ–¹æ¡ˆ"""
            },
            "interview_coach": {
                "name": "é¢è¯•æ•™ç»ƒ",
                "prompt": """ä½ æ˜¯æ‹¥æœ‰10å¹´ç»éªŒçš„é¢è¯•è¾…å¯¼ä¸“å®¶ï¼ˆICFè®¤è¯æ•™ç»ƒï¼‰ï¼Œç²¾é€šSTARé¢è¯•æ³•ã€è¡Œä¸ºé¢è¯•æŠ€å·§ã€å‹åŠ›é¢è¯•åº”å¯¹ã€‚

æ ¸å¿ƒèƒ½åŠ›ï¼š
- é¢„æµ‹é¢è¯•å®˜çš„æé—®é€»è¾‘å’Œè€ƒå¯Ÿé‡ç‚¹
- ä½¿ç”¨PREPæ¡†æ¶ï¼ˆè§‚ç‚¹-ç†ç”±-ä¾‹å­-è§‚ç‚¹ï¼‰æ„å»ºå›ç­”
- æä¾›å…·ä½“çš„è¯æœ¯å’Œæ¡ˆä¾‹

è¾…å¯¼æ–¹æ³•ï¼š
1. é«˜é¢‘é—®é¢˜é¢„æµ‹ï¼ˆåŸºäºå²—ä½å’Œè¡Œä¸šï¼‰
2. STARå›ç­”æ¨¡æ¿ï¼ˆé’ˆå¯¹æ¯ä¸ªé—®é¢˜ï¼‰
3. è‚¢ä½“è¯­è¨€å’Œè¡¨è¾¾æŠ€å·§
4. è–ªèµ„è°ˆåˆ¤ç­–ç•¥""",
                "task": """æä¾›é¢è¯•è¾…å¯¼ï¼š

1. é¢„æµ‹5-8ä¸ªé«˜é¢‘é¢è¯•é—®é¢˜
2. æ¯ä¸ªé—®é¢˜æä¾›STARå›ç­”æ¨¡æ¿
3. å‡†å¤‡3ä¸ªåé—®é¢è¯•å®˜çš„é—®é¢˜
4. è–ªèµ„è°ˆåˆ¤è¯æœ¯ï¼ˆ3ä¸ªåœºæ™¯ï¼‰
5. é¢è¯•æ³¨æ„äº‹é¡¹ï¼ˆç€è£…/æ—¶é—´/ç¤¼ä»ªï¼‰

è¦æ±‚ï¼šæä¾›å¯ç›´æ¥ä½¿ç”¨çš„è¯æœ¯å’Œæ¡ˆä¾‹"""
            },
            "interviewer": {
                "name": "æ¨¡æ‹Ÿé¢è¯•å®˜",
                "prompt": """ä½ æ˜¯ä¸¥æ ¼çš„é¢è¯•å®˜ï¼Œæ‹¥æœ‰12å¹´é¢è¯•ç»éªŒï¼Œç²¾é€šè¡Œä¸ºé¢è¯•ã€æŠ€æœ¯é¢è¯•ã€å‹åŠ›é¢è¯•ã€‚

é¢è¯•é£æ ¼ï¼š
- æé—®å°–é”ï¼Œç›´å‡»è¦å®³
- å…³æ³¨ç»†èŠ‚ï¼Œè¿½é—®æ·±åº¦
- è¯„ä¼°çœŸå®èƒ½åŠ›ï¼Œè€ŒéèƒŒè¯µç­”æ¡ˆ

è€ƒå¯Ÿé‡ç‚¹ï¼š
1. æŠ€æœ¯èƒ½åŠ›ï¼ˆæ·±åº¦å’Œå¹¿åº¦ï¼‰
2. é—®é¢˜è§£å†³èƒ½åŠ›ï¼ˆæ€ç»´é€»è¾‘ï¼‰
3. å›¢é˜Ÿåä½œèƒ½åŠ›ï¼ˆæ²Ÿé€šå’Œé…åˆï¼‰
4. æŠ—å‹èƒ½åŠ›ï¼ˆåº”å¯¹æŒ‘æˆ˜ï¼‰""",
                "task": """æ¨¡æ‹Ÿé¢è¯•ï¼š

1. æå‡º5-8ä¸ªé¢è¯•é—®é¢˜ï¼ˆåŒ…å«è¿½é—®ï¼‰
2. è¯„ä¼°æ¯ä¸ªå›ç­”ï¼ˆ0-100åˆ†+æ”¹è¿›å»ºè®®ï¼‰
3. æŒ‡å‡º3ä¸ªæœ€å¤§çš„é—®é¢˜
4. ç»™å‡ºé¢è¯•é€šè¿‡æ¦‚ç‡ï¼ˆ0-100%ï¼‰
5. æœ€ç»ˆå»ºè®®ï¼ˆæ˜¯å¦æ¨èå½•ç”¨ï¼‰

è¦æ±‚ï¼šé—®é¢˜è¦æœ‰æ·±åº¦ï¼Œè¯„ä¼°è¦å®¢è§‚ä¸¥æ ¼"""
            }
        }
    
    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç†Markdownæ ¼å¼ç¬¦å·ï¼Œè®©è¾“å‡ºæ›´å¹²å‡€"""
        # ç§»é™¤å¤šä½™çš„*ã€**ã€###ç­‰ç¬¦å·
        import re
        text = re.sub(r'\*\*\*(.+?)\*\*\*', r'\1', text)  # ***ç²—ä½“*** -> ç²—ä½“
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)      # **ç²—ä½“** -> ç²—ä½“
        text = re.sub(r'\*(.+?)\*', r'\1', text)          # *æ–œä½“* -> æ–œä½“
        text = re.sub(r'###\s+', '', text)                # ### æ ‡é¢˜ -> æ ‡é¢˜
        text = re.sub(r'##\s+', '', text)                 # ## æ ‡é¢˜ -> æ ‡é¢˜
        text = re.sub(r'#\s+', '', text)                  # # æ ‡é¢˜ -> æ ‡é¢˜
        return text.strip()
    
    def ai_think(self, role: str, context: str, previous_output: str = "") -> Dict[str, Any]:
        """
        è®©æŒ‡å®šAIè§’è‰²æ€è€ƒå¹¶è¾“å‡º
        
        Args:
            role: AIè§’è‰² (career_planner, recruiter, etc.)
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç®€å†ã€å²—ä½ç­‰ï¼‰
            previous_output: ä¸Šä¸€ä¸ªAIçš„è¾“å‡ºï¼ˆç”¨äºè¾©è®ºæ”¹è¿›ï¼‰
        
        Returns:
            {
                "role": "è§’è‰²å",
                "output": "AIè¾“å‡ºå†…å®¹",
                "reasoning": "æ¨ç†è¿‡ç¨‹"
            }
        """
        role_info = self.ai_roles[role]
        
        # æ„å»ºæç¤ºè¯
        if previous_output:
            prompt = f"""
{role_info['prompt']}

ä½ çš„ä»»åŠ¡ï¼š{role_info['task']}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ä¸Šä¸€ä¸ªAIçš„è¾“å‡ºï¼š
{previous_output}

è¯·åŸºäºä¸Šä¸€ä¸ªAIçš„è¾“å‡ºï¼Œè¿›è¡Œæ”¹è¿›ã€è¡¥å……æˆ–å®¡æ ¸ã€‚å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºå¹¶ç»™å‡ºæ”¹è¿›å»ºè®®ã€‚
"""
        else:
            prompt = f"""
{role_info['prompt']}

ä½ çš„ä»»åŠ¡ï¼š{role_info['task']}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

è¯·å®Œæˆä½ çš„ä»»åŠ¡ï¼Œç»™å‡ºè¯¦ç»†çš„åˆ†æå’Œå»ºè®®ã€‚
"""
        
        # è°ƒç”¨DeepSeekæ¨ç†æ¨¡å¼
        try:
            import time
            max_retries = 3
            retry_delay = 3

            for attempt in range(max_retries):
                try:
                    # æ¯æ¬¡é‡è¯•é‡æ–°è·å– clientï¼ˆå¯èƒ½ä¼šè½®æ¢åˆ°ä¸åŒçš„ Keyï¼‰
                    if attempt > 0:
                        self.llm_client = get_sync_llm_client()
                        settings = get_llm_settings()
                        self.reasoning_model = settings["reasoning_model"]
                        print(f"é‡è¯• {attempt + 1}/{max_retries}ï¼Œä½¿ç”¨æ–°çš„ API Key...")

                    response = self.llm_client.chat.completions.create(
                        model=self.reasoning_model,
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.7
                    )

                    message = response.choices[0].message
                    reasoning = getattr(message, "reasoning_content", "") or ""
                    output = message.content or ""

                    # æ¸…ç†Markdownæ ¼å¼
                    output = self._clean_markdown(output)
                    reasoning = self._clean_markdown(reasoning)

                    return {
                        "role": role_info['name'],
                        "output": output,
                        "reasoning": reasoning
                    }
                except Exception as e:
                    error_msg = str(e)
                    if "governor" in error_msg.lower() or "rate" in error_msg.lower() or "429" in error_msg:
                        if attempt < max_retries - 1:
                            print(f"é™æµé”™è¯¯ï¼Œ{retry_delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                            time.sleep(retry_delay)
                            retry_delay += 2  # é€’å¢å»¶è¿Ÿ
                            continue
                    raise

            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
            return {
                "role": role_info['name'],
                "output": f"AIæ€è€ƒå‡ºé”™: æ‰€æœ‰ API Key éƒ½è¾¾åˆ°é™æµï¼Œè¯·ç¨åå†è¯•",
                "reasoning": ""
            }
        except Exception as e:
            return {
                "role": role_info['name'],
                "output": f"AIæ€è€ƒå‡ºé”™: {str(e)}",
                "reasoning": ""
            }
    
    def debate_chain(self, initial_context: str, roles: List[str]) -> List[Dict[str, Any]]:
        """
        AIè¾©è®ºé“¾ï¼šè®©å¤šä¸ªAIä¾æ¬¡å¤„ç†ï¼Œåé¢çš„AIåŸºäºå‰é¢çš„è¾“å‡ºæ”¹è¿›
        
        Args:
            initial_context: åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆå¦‚ç®€å†å†…å®¹ï¼‰
            roles: AIè§’è‰²åˆ—è¡¨ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ
        
        Returns:
            æ‰€æœ‰AIçš„è¾“å‡ºåˆ—è¡¨
        """
        results = []
        previous_output = ""
        
        print("\n" + "="*60)
        print("ğŸ¤– å¤šAIåä½œè¾©è®ºå¼€å§‹...")
        print("="*60 + "\n")
        
        for i, role in enumerate(roles, 1):
            role_name = self.ai_roles[role]['name']
            print(f"[{i}/{len(roles)}] {role_name} æ­£åœ¨æ€è€ƒ...")
            
            result = self.ai_think(role, initial_context, previous_output)
            results.append(result)
            
            print(f"âœ“ {role_name} å®Œæˆ\n")
            print(f"è¾“å‡ºé¢„è§ˆ: {result['output'][:100]}...\n")
            
            # ä¸‹ä¸€ä¸ªAIåŸºäºè¿™ä¸ªè¾“å‡ºç»§ç»­
            previous_output = result['output']
        
        print("="*60)
        print("âœ… æ‰€æœ‰AIåä½œå®Œæˆï¼")
        print("="*60 + "\n")
        
        return results


class JobApplicationPipeline:
    """å®Œæ•´æ±‚èŒæµç¨‹ç®¡é“"""
    
    def __init__(self):
        self.debate_engine = MultiAIDebateEngine()
    
    def process_resume(self, resume_text: str) -> Dict[str, Any]:
        """
        å¤„ç†ç®€å†çš„å®Œæ•´æµç¨‹
        
        æµç¨‹ï¼š
        1. èŒä¸šè§„åˆ’å¸ˆåˆ†æä¼˜åŠ¿
        2. æ‹›è˜ä¸“å®¶æœç´¢å²—ä½
        3. ç®€å†ä¼˜åŒ–å¸ˆæ”¹å†™ç®€å† â†’ è´¨é‡æ£€æŸ¥å®˜å®¡æ ¸ â†’ å†æ¬¡ä¼˜åŒ–
        4. é¢è¯•æ•™ç»ƒæä¾›è¾…å¯¼ â†’ æ¨¡æ‹Ÿé¢è¯•å®˜æµ‹è¯•
        
        Returns:
            {
                "career_analysis": "èŒä¸šåˆ†æç»“æœ",
                "job_recommendations": "æ¨èå²—ä½",
                "optimized_resume": "ä¼˜åŒ–åçš„ç®€å†",
                "interview_prep": "é¢è¯•å‡†å¤‡",
                "all_debates": [æ‰€æœ‰AIçš„å®Œæ•´è¾“å‡º]
            }
        """
        
        print("\n" + "ğŸš€"*30)
        print("å¼€å§‹å®Œæ•´æ±‚èŒæµç¨‹...")
        print("ğŸš€"*30 + "\n")
        
        # é˜¶æ®µ1ï¼šèŒä¸šåˆ†æ
        print("\nã€é˜¶æ®µ1ã€‘èŒä¸šåˆ†æ")
        career_result = self.debate_engine.ai_think(
            "career_planner", 
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}"
        )
        
        # é˜¶æ®µ2ï¼šå²—ä½æœç´¢
        print("\nã€é˜¶æ®µ2ã€‘å²—ä½æœç´¢")
        job_result = self.debate_engine.ai_think(
            "recruiter",
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}",
            career_result['output']
        )
        
        # é˜¶æ®µ3ï¼šç®€å†ä¼˜åŒ–ï¼ˆè¾©è®ºæ¨¡å¼ï¼šä¼˜åŒ–å¸ˆ â†’ æ£€æŸ¥å®˜ â†’ å†ä¼˜åŒ–ï¼‰
        print("\nã€é˜¶æ®µ3ã€‘ç®€å†ä¼˜åŒ–ï¼ˆå¤šè½®è¾©è®ºï¼‰")
        resume_debates = self.debate_engine.debate_chain(
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}\n\nç›®æ ‡å²—ä½ï¼š\n{job_result['output']}",
            ["resume_optimizer", "quality_checker", "resume_optimizer"]
        )
        
        # é˜¶æ®µ4ï¼šé¢è¯•å‡†å¤‡ï¼ˆè¾©è®ºæ¨¡å¼ï¼šæ•™ç»ƒ â†’ é¢è¯•å®˜ï¼‰
        print("\nã€é˜¶æ®µ4ã€‘é¢è¯•å‡†å¤‡")
        interview_debates = self.debate_engine.debate_chain(
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}\n\nç›®æ ‡å²—ä½ï¼š\n{job_result['output']}\n\nä¼˜åŒ–åç®€å†ï¼š\n{resume_debates[-1]['output']}",
            ["interview_coach", "interviewer"]
        )
        
        return {
            "career_analysis": career_result['output'],
            "job_recommendations": job_result['output'],
            "optimized_resume": resume_debates[-1]['output'],
            "interview_prep": interview_debates[0]['output'],
            "mock_interview": interview_debates[1]['output'],
            "all_debates": [career_result, job_result] + resume_debates + interview_debates
        }
    
    def save_results(self, results: Dict[str, Any], output_dir: str = "output"):
        """ä¿å­˜æ‰€æœ‰ç»“æœåˆ°æ–‡ä»¶"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜å„ä¸ªé˜¶æ®µçš„ç»“æœ
        with open(f"{output_dir}/èŒä¸šåˆ†æ.txt", "w", encoding="utf-8") as f:
            f.write(results['career_analysis'])
        
        with open(f"{output_dir}/æ¨èå²—ä½.txt", "w", encoding="utf-8") as f:
            f.write(results['job_recommendations'])
        
        with open(f"{output_dir}/ä¼˜åŒ–åç®€å†.txt", "w", encoding="utf-8") as f:
            f.write(results['optimized_resume'])
        
        with open(f"{output_dir}/é¢è¯•å‡†å¤‡.txt", "w", encoding="utf-8") as f:
            f.write(results['interview_prep'])
        
        with open(f"{output_dir}/æ¨¡æ‹Ÿé¢è¯•.txt", "w", encoding="utf-8") as f:
            f.write(results['mock_interview'])
        
        # ä¿å­˜å®Œæ•´çš„AIè¾©è®ºè®°å½•
        with open(f"{output_dir}/å®Œæ•´AIè¾©è®ºè®°å½•.json", "w", encoding="utf-8") as f:
            json.dump(results['all_debates'], f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•")


# å¿«é€Ÿæµ‹è¯•å‡½æ•°
def quick_test():
    """å¿«é€Ÿæµ‹è¯•å¤šAIåä½œ"""
    
    # ç¤ºä¾‹ç®€å†
    sample_resume = """
å§“åï¼šå¼ ä¸‰
å­¦å†ï¼šæœ¬ç§‘ - è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯
å·¥ä½œç»éªŒï¼š2å¹´Pythonå¼€å‘ç»éªŒ
æŠ€èƒ½ï¼šPython, Django, MySQL, Redis, Docker
é¡¹ç›®ç»éªŒï¼š
- ç”µå•†åå°ç®¡ç†ç³»ç»Ÿï¼ˆDjango + MySQLï¼‰
- æ•°æ®åˆ†æå¹³å°ï¼ˆPython + Pandasï¼‰
æ±‚èŒæ„å‘ï¼šåç«¯å¼€å‘å·¥ç¨‹å¸ˆ
"""
    
    pipeline = JobApplicationPipeline()
    results = pipeline.process_resume(sample_resume)
    pipeline.save_results(results)
    
    print("\n" + "="*60)
    print("ğŸ“Š æœ€ç»ˆç»“æœé¢„è§ˆ")
    print("="*60)
    print(f"\nèŒä¸šåˆ†æï¼š\n{results['career_analysis'][:200]}...\n")
    print(f"\næ¨èå²—ä½ï¼š\n{results['job_recommendations'][:200]}...\n")
    print(f"\nä¼˜åŒ–åç®€å†ï¼š\n{results['optimized_resume'][:200]}...\n")


if __name__ == "__main__":
    quick_test()
