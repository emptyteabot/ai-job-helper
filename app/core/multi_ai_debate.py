"""
å¤šAIåä½œè¾©è®ºç³»ç»Ÿ - æ ¸å¿ƒå¼•æ“
è®©å¤šä¸ªAIåƒè¾©è®ºä¸€æ ·åä½œï¼Œäº’ç›¸æ”¹è¿›è¾“å‡º
"""

import os
import json
from typing import List, Dict, Any
from openai import OpenAI
from dotenv import load_dotenv
from app.core.llm_client import get_sync_llm_client, get_llm_settings

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

class MultiAIDebateEngine:
    """å¤šAIè¾©è®ºå¼•æ“ - è®©AIäº’ç›¸è¾©è®ºã€æ”¹è¿›ã€æ£€æŸ¥"""
    
    def __init__(self):
        self.llm_client = get_sync_llm_client()
        settings = get_llm_settings()
        self.reasoning_model = settings["reasoning_model"]
        
        # å®šä¹‰6ä¸ªAIè§’è‰²
        self.ai_roles = {
            "career_planner": {
                "name": "èŒä¸šè§„åˆ’å¸ˆ",
                "prompt": "ä½ æ˜¯èµ„æ·±èŒä¸šè§„åˆ’å¸ˆï¼Œæ“…é•¿åˆ†ææ±‚èŒè€…ä¼˜åŠ¿ã€å®šä½èŒä¸šæ–¹å‘ã€‚",
                "task": "åˆ†æç®€å†ï¼Œæ‰¾å‡ºæ ¸å¿ƒä¼˜åŠ¿å’Œæœ€é€‚åˆçš„èŒä¸šæ–¹å‘"
            },
            "recruiter": {
                "name": "æ‹›è˜ä¸“å®¶",
                "prompt": "ä½ æ˜¯æ‹›è˜è¡Œä¸šä¸“å®¶ï¼Œäº†è§£å„å¤§æ‹›è˜å¹³å°å’Œå²—ä½éœ€æ±‚ã€‚",
                "task": "æ ¹æ®æ±‚èŒè€…ä¼˜åŠ¿ï¼Œæœç´¢æœ€åŒ¹é…çš„å²—ä½"
            },
            "resume_optimizer": {
                "name": "ç®€å†ä¼˜åŒ–å¸ˆ",
                "prompt": "ä½ æ˜¯ç®€å†ä¼˜åŒ–ä¸“å®¶ï¼Œæ“…é•¿é’ˆå¯¹å²—ä½éœ€æ±‚æ”¹å†™ç®€å†ã€‚",
                "task": "é’ˆå¯¹ç›®æ ‡å²—ä½ï¼Œä¼˜åŒ–ç®€å†å†…å®¹"
            },
            "quality_checker": {
                "name": "è´¨é‡æ£€æŸ¥å®˜",
                "prompt": "ä½ æ˜¯è´¨é‡å®¡æ ¸ä¸“å®¶ï¼Œè´Ÿè´£æ£€æŸ¥ç®€å†æ˜¯å¦ç¬¦åˆå²—ä½è¦æ±‚ã€‚",
                "task": "å®¡æ ¸ä¼˜åŒ–åçš„ç®€å†ï¼ŒæŒ‡å‡ºé—®é¢˜å¹¶è¦æ±‚æ”¹è¿›"
            },
            "interview_coach": {
                "name": "é¢è¯•æ•™ç»ƒ",
                "prompt": "ä½ æ˜¯é¢è¯•è¾…å¯¼ä¸“å®¶ï¼Œå¸®åŠ©æ±‚èŒè€…å‡†å¤‡é¢è¯•ã€‚",
                "task": "æ ¹æ®å²—ä½å’Œç®€å†ï¼Œæä¾›é¢è¯•è¾…å¯¼å»ºè®®"
            },
            "interviewer": {
                "name": "æ¨¡æ‹Ÿé¢è¯•å®˜",
                "prompt": "ä½ æ˜¯ä¸¥æ ¼çš„é¢è¯•å®˜ï¼Œè´Ÿè´£æ¨¡æ‹Ÿé¢è¯•å¹¶æå‡ºå°–é”é—®é¢˜ã€‚",
                "task": "æ¨¡æ‹ŸçœŸå®é¢è¯•åœºæ™¯ï¼Œæå‡ºé—®é¢˜å¹¶è¯„ä¼°å›ç­”"
            }
        }
    
    def _clean_markdown(self, text: str) -> str:
        """æ¸…ç†Markdownæ ¼å¼ç¬¦å·ï¼Œè®©è¾“å‡ºæ›´å¹²å‡€"""
        # ç§»é™¤å¤šä½™çš„*ã€**ã€###ç­‰ç¬¦å·
        import re
        text = re.sub(r'\*\*\*(.+?)\*\*\*', r'\1', text)  # ***ç²—ä½“*** -> ç²—ä½“
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)      # **ç²—ä½“** -> ç²—ä½“
        text = re.sub(r'\*(.+?)\*', r'\1', text)          # *æ–œä½“* -> æ–œä½“
        text = re.sub(r'###\s+', '', text)                # ### æ ‡é¢˜ -> æ ‡é¢˜
        text = re.sub(r'##\s+', '', text)                 # ## æ ‡é¢˜ -> æ ‡é¢˜
        text = re.sub(r'#\s+', '', text)                  # # æ ‡é¢˜ -> æ ‡é¢˜
        return text.strip()
    
    def ai_think(self, role: str, context: str, previous_output: str = "") -> Dict[str, Any]:
        """
        è®©æŒ‡å®šAIè§’è‰²æ€è€ƒå¹¶è¾“å‡º
        
        Args:
            role: AIè§’è‰² (career_planner, recruiter, etc.)
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆç®€å†ã€å²—ä½ç­‰ï¼‰
            previous_output: ä¸Šä¸€ä¸ªAIçš„è¾“å‡ºï¼ˆç”¨äºè¾©è®ºæ”¹è¿›ï¼‰
        
        Returns:
            {
                "role": "è§’è‰²å",
                "output": "AIè¾“å‡ºå†…å®¹",
                "reasoning": "æ¨ç†è¿‡ç¨‹"
            }
        """
        role_info = self.ai_roles[role]
        
        # æ„å»ºæç¤ºè¯
        if previous_output:
            prompt = f"""
{role_info['prompt']}

ä½ çš„ä»»åŠ¡ï¼š{role_info['task']}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

ä¸Šä¸€ä¸ªAIçš„è¾“å‡ºï¼š
{previous_output}

è¯·åŸºäºä¸Šä¸€ä¸ªAIçš„è¾“å‡ºï¼Œè¿›è¡Œæ”¹è¿›ã€è¡¥å……æˆ–å®¡æ ¸ã€‚å¦‚æœå‘ç°é—®é¢˜ï¼Œè¯·æ˜ç¡®æŒ‡å‡ºå¹¶ç»™å‡ºæ”¹è¿›å»ºè®®ã€‚
"""
        else:
            prompt = f"""
{role_info['prompt']}

ä½ çš„ä»»åŠ¡ï¼š{role_info['task']}

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

è¯·å®Œæˆä½ çš„ä»»åŠ¡ï¼Œç»™å‡ºè¯¦ç»†çš„åˆ†æå’Œå»ºè®®ã€‚
"""
        
        # è°ƒç”¨DeepSeekæ¨ç†æ¨¡å¼
        try:
            response = self.llm_client.chat.completions.create(
                model=self.reasoning_model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7
            )
            
            message = response.choices[0].message
            reasoning = getattr(message, "reasoning_content", "") or ""
            output = message.content or ""
            
            # æ¸…ç†Markdownæ ¼å¼
            output = self._clean_markdown(output)
            reasoning = self._clean_markdown(reasoning)
            
            return {
                "role": role_info['name'],
                "output": output,
                "reasoning": reasoning
            }
        except Exception as e:
            return {
                "role": role_info['name'],
                "output": f"AIæ€è€ƒå‡ºé”™: {str(e)}",
                "reasoning": ""
            }
    
    def debate_chain(self, initial_context: str, roles: List[str]) -> List[Dict[str, Any]]:
        """
        AIè¾©è®ºé“¾ï¼šè®©å¤šä¸ªAIä¾æ¬¡å¤„ç†ï¼Œåé¢çš„AIåŸºäºå‰é¢çš„è¾“å‡ºæ”¹è¿›
        
        Args:
            initial_context: åˆå§‹ä¸Šä¸‹æ–‡ï¼ˆå¦‚ç®€å†å†…å®¹ï¼‰
            roles: AIè§’è‰²åˆ—è¡¨ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ
        
        Returns:
            æ‰€æœ‰AIçš„è¾“å‡ºåˆ—è¡¨
        """
        results = []
        previous_output = ""
        
        print("\n" + "="*60)
        print("ğŸ¤– å¤šAIåä½œè¾©è®ºå¼€å§‹...")
        print("="*60 + "\n")
        
        for i, role in enumerate(roles, 1):
            role_name = self.ai_roles[role]['name']
            print(f"[{i}/{len(roles)}] {role_name} æ­£åœ¨æ€è€ƒ...")
            
            result = self.ai_think(role, initial_context, previous_output)
            results.append(result)
            
            print(f"âœ“ {role_name} å®Œæˆ\n")
            print(f"è¾“å‡ºé¢„è§ˆ: {result['output'][:100]}...\n")
            
            # ä¸‹ä¸€ä¸ªAIåŸºäºè¿™ä¸ªè¾“å‡ºç»§ç»­
            previous_output = result['output']
        
        print("="*60)
        print("âœ… æ‰€æœ‰AIåä½œå®Œæˆï¼")
        print("="*60 + "\n")
        
        return results


class JobApplicationPipeline:
    """å®Œæ•´æ±‚èŒæµç¨‹ç®¡é“"""
    
    def __init__(self):
        self.debate_engine = MultiAIDebateEngine()
    
    def process_resume(self, resume_text: str) -> Dict[str, Any]:
        """
        å¤„ç†ç®€å†çš„å®Œæ•´æµç¨‹
        
        æµç¨‹ï¼š
        1. èŒä¸šè§„åˆ’å¸ˆåˆ†æä¼˜åŠ¿
        2. æ‹›è˜ä¸“å®¶æœç´¢å²—ä½
        3. ç®€å†ä¼˜åŒ–å¸ˆæ”¹å†™ç®€å† â†’ è´¨é‡æ£€æŸ¥å®˜å®¡æ ¸ â†’ å†æ¬¡ä¼˜åŒ–
        4. é¢è¯•æ•™ç»ƒæä¾›è¾…å¯¼ â†’ æ¨¡æ‹Ÿé¢è¯•å®˜æµ‹è¯•
        
        Returns:
            {
                "career_analysis": "èŒä¸šåˆ†æç»“æœ",
                "job_recommendations": "æ¨èå²—ä½",
                "optimized_resume": "ä¼˜åŒ–åçš„ç®€å†",
                "interview_prep": "é¢è¯•å‡†å¤‡",
                "all_debates": [æ‰€æœ‰AIçš„å®Œæ•´è¾“å‡º]
            }
        """
        
        print("\n" + "ğŸš€"*30)
        print("å¼€å§‹å®Œæ•´æ±‚èŒæµç¨‹...")
        print("ğŸš€"*30 + "\n")
        
        # é˜¶æ®µ1ï¼šèŒä¸šåˆ†æ
        print("\nã€é˜¶æ®µ1ã€‘èŒä¸šåˆ†æ")
        career_result = self.debate_engine.ai_think(
            "career_planner", 
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}"
        )
        
        # é˜¶æ®µ2ï¼šå²—ä½æœç´¢
        print("\nã€é˜¶æ®µ2ã€‘å²—ä½æœç´¢")
        job_result = self.debate_engine.ai_think(
            "recruiter",
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}",
            career_result['output']
        )
        
        # é˜¶æ®µ3ï¼šç®€å†ä¼˜åŒ–ï¼ˆè¾©è®ºæ¨¡å¼ï¼šä¼˜åŒ–å¸ˆ â†’ æ£€æŸ¥å®˜ â†’ å†ä¼˜åŒ–ï¼‰
        print("\nã€é˜¶æ®µ3ã€‘ç®€å†ä¼˜åŒ–ï¼ˆå¤šè½®è¾©è®ºï¼‰")
        resume_debates = self.debate_engine.debate_chain(
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}\n\nç›®æ ‡å²—ä½ï¼š\n{job_result['output']}",
            ["resume_optimizer", "quality_checker", "resume_optimizer"]
        )
        
        # é˜¶æ®µ4ï¼šé¢è¯•å‡†å¤‡ï¼ˆè¾©è®ºæ¨¡å¼ï¼šæ•™ç»ƒ â†’ é¢è¯•å®˜ï¼‰
        print("\nã€é˜¶æ®µ4ã€‘é¢è¯•å‡†å¤‡")
        interview_debates = self.debate_engine.debate_chain(
            f"ç®€å†å†…å®¹ï¼š\n{resume_text}\n\nç›®æ ‡å²—ä½ï¼š\n{job_result['output']}\n\nä¼˜åŒ–åç®€å†ï¼š\n{resume_debates[-1]['output']}",
            ["interview_coach", "interviewer"]
        )
        
        return {
            "career_analysis": career_result['output'],
            "job_recommendations": job_result['output'],
            "optimized_resume": resume_debates[-1]['output'],
            "interview_prep": interview_debates[0]['output'],
            "mock_interview": interview_debates[1]['output'],
            "all_debates": [career_result, job_result] + resume_debates + interview_debates
        }
    
    def save_results(self, results: Dict[str, Any], output_dir: str = "output"):
        """ä¿å­˜æ‰€æœ‰ç»“æœåˆ°æ–‡ä»¶"""
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜å„ä¸ªé˜¶æ®µçš„ç»“æœ
        with open(f"{output_dir}/èŒä¸šåˆ†æ.txt", "w", encoding="utf-8") as f:
            f.write(results['career_analysis'])
        
        with open(f"{output_dir}/æ¨èå²—ä½.txt", "w", encoding="utf-8") as f:
            f.write(results['job_recommendations'])
        
        with open(f"{output_dir}/ä¼˜åŒ–åç®€å†.txt", "w", encoding="utf-8") as f:
            f.write(results['optimized_resume'])
        
        with open(f"{output_dir}/é¢è¯•å‡†å¤‡.txt", "w", encoding="utf-8") as f:
            f.write(results['interview_prep'])
        
        with open(f"{output_dir}/æ¨¡æ‹Ÿé¢è¯•.txt", "w", encoding="utf-8") as f:
            f.write(results['mock_interview'])
        
        # ä¿å­˜å®Œæ•´çš„AIè¾©è®ºè®°å½•
        with open(f"{output_dir}/å®Œæ•´AIè¾©è®ºè®°å½•.json", "w", encoding="utf-8") as f:
            json.dump(results['all_debates'], f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æ‰€æœ‰ç»“æœå·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•")


# å¿«é€Ÿæµ‹è¯•å‡½æ•°
def quick_test():
    """å¿«é€Ÿæµ‹è¯•å¤šAIåä½œ"""
    
    # ç¤ºä¾‹ç®€å†
    sample_resume = """
å§“åï¼šå¼ ä¸‰
å­¦å†ï¼šæœ¬ç§‘ - è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯
å·¥ä½œç»éªŒï¼š2å¹´Pythonå¼€å‘ç»éªŒ
æŠ€èƒ½ï¼šPython, Django, MySQL, Redis, Docker
é¡¹ç›®ç»éªŒï¼š
- ç”µå•†åå°ç®¡ç†ç³»ç»Ÿï¼ˆDjango + MySQLï¼‰
- æ•°æ®åˆ†æå¹³å°ï¼ˆPython + Pandasï¼‰
æ±‚èŒæ„å‘ï¼šåç«¯å¼€å‘å·¥ç¨‹å¸ˆ
"""
    
    pipeline = JobApplicationPipeline()
    results = pipeline.process_resume(sample_resume)
    pipeline.save_results(results)
    
    print("\n" + "="*60)
    print("ğŸ“Š æœ€ç»ˆç»“æœé¢„è§ˆ")
    print("="*60)
    print(f"\nèŒä¸šåˆ†æï¼š\n{results['career_analysis'][:200]}...\n")
    print(f"\næ¨èå²—ä½ï¼š\n{results['job_recommendations'][:200]}...\n")
    print(f"\nä¼˜åŒ–åç®€å†ï¼š\n{results['optimized_resume'][:200]}...\n")


if __name__ == "__main__":
    quick_test()
