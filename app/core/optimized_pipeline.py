"""
ä¼˜åŒ–çš„ AI æ±‚èŒæµç¨‹ - ä½¿ç”¨æ¨ç†æ¨¡å‹ + ç§‘å­¦çš„ Agent é¡ºåº
4ä¸ªæ ¸å¿ƒ Agentï¼Œé€»è¾‘æ¸…æ™°ï¼Œæ•ˆæœæ›´å¥½
"""

import os
import time
from typing import Dict, Any
from app.core.llm_client import get_sync_llm_client, get_llm_settings


class OptimizedJobPipeline:
    """ä¼˜åŒ–çš„æ±‚èŒæµç¨‹ - 4ä¸ªæ ¸å¿ƒAgent"""

    def __init__(self):
        self.llm_client = get_sync_llm_client()
        settings = get_llm_settings()
        self.reasoning_model = settings["reasoning_model"]

        # 4ä¸ªæ ¸å¿ƒAIè§’è‰² - ç§‘å­¦æ’åº
        self.agents = {
            "career_analyst": {
                "name": "èŒä¸šåˆ†æå¸ˆ",
                "prompt": """ä½ æ˜¯GCDFè®¤è¯èŒä¸šåˆ†æå¸ˆï¼Œ15å¹´ç»éªŒï¼Œä¸“æ³¨å®ä¹ ç”ŸèŒä¸šè§„åˆ’ã€‚

ä»»åŠ¡ï¼šæ·±åº¦åˆ†æç®€å†ï¼Œè¾“å‡ºå®Œæ•´çš„èŒä¸šè¯„ä¼°æŠ¥å‘Šï¼ˆé’ˆå¯¹å®ä¹ ç”Ÿï¼‰

åˆ†ææ¡†æ¶ï¼š
1. **SWOTåˆ†æ**ï¼ˆä¼˜åŠ¿/åŠ£åŠ¿/æœºä¼š/å¨èƒï¼Œå„2-3æ¡ï¼Œå…³æ³¨å®ä¹ ç»å†å’Œé¡¹ç›®ï¼‰
2. **æ ¸å¿ƒç«äº‰åŠ›**ï¼ˆ3-5ç‚¹ï¼ŒåŒ…å«é‡åŒ–è¯æ®ï¼Œçªå‡ºå­¦ä¹ èƒ½åŠ›å’Œæ½œåŠ›ï¼‰
3. **å®ä¹ å²—ä½å®šä½**ï¼ˆ3ä¸ªæ–¹å‘+åŒ¹é…åº¦è¯„åˆ†0-100ï¼Œè€ƒè™‘ä¸“ä¸šå’Œå…´è¶£ï¼‰
4. **æŠ€èƒ½çŸ©é˜µ**ï¼ˆç¡¬æŠ€èƒ½/è½¯æŠ€èƒ½/å¯è¿ç§»æŠ€èƒ½ï¼Œæ ‡æ³¨æŒæ¡ç¨‹åº¦ï¼‰
5. **å‘å±•è·¯å¾„**ï¼ˆå®ä¹ æœŸ3-6ä¸ªæœˆ/è½¬æ­£å1å¹´/èŒä¸šå‘å±•3å¹´ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- 60%ä»¥ä¸Šå†…å®¹åŒ…å«é‡åŒ–æ•°æ®
- æ¯æ¡å»ºè®®åŒ…å«å…·ä½“è¡ŒåŠ¨
- å…³æ³¨å®ä¹ ç”Ÿç‰¹ç‚¹ï¼šå­¦ä¹ èƒ½åŠ›ã€æˆé•¿æ½œåŠ›ã€é€‚åº”èƒ½åŠ›
- æ€»å­—æ•°500-600å­—""",
            },

            "job_matcher": {
                "name": "å²—ä½åŒ¹é…ä¸“å®¶",
                "prompt": """ä½ æ˜¯SHRM-SCPè®¤è¯æ‹›è˜ä¸“å®¶ï¼Œ12å¹´ç»éªŒï¼Œä¸“æ³¨å®ä¹ ç”Ÿæ‹›è˜ã€‚

ä»»åŠ¡ï¼šåŸºäºèŒä¸šåˆ†æï¼Œæ¨èæœ€åŒ¹é…çš„å®ä¹ å²—ä½å¹¶ä¼˜åŒ–ç®€å†

è¾“å‡ºå†…å®¹ï¼š
1. **å®ä¹ å²—ä½æ¨è**ï¼ˆ5ä¸ªå²—ä½ï¼šèŒä½/å…¬å¸/è–ªèµ„/è¦æ±‚/åŒ¹é…åº¦ï¼‰
   - ä¼˜å…ˆæ¨èå¤§å‚å®ä¹ ã€ç‹¬è§’å…½å…¬å¸ã€æˆé•¿å‹ä¼ä¸š
   - æ ‡æ³¨æ˜¯å¦æä¾›è½¬æ­£æœºä¼š
2. **ç®€å†ä¼˜åŒ–**ï¼ˆä½¿ç”¨STARæ³•åˆ™é‡å†™3-5æ¡ç»å†ï¼‰
   - çªå‡ºé¡¹ç›®ç»éªŒã€è¯¾ç¨‹ä½œä¸šã€ç¤¾å›¢æ´»åŠ¨
   - å¼ºè°ƒå­¦ä¹ èƒ½åŠ›å’Œæˆé•¿æ½œåŠ›
3. **ATSä¼˜åŒ–**ï¼ˆå…³é”®è¯æå–10-15ä¸ª+å¯†åº¦å»ºè®®ï¼‰
   - é’ˆå¯¹å®ä¹ ç”Ÿå²—ä½çš„å…³é”®è¯
4. **æŠ•é€’ç­–ç•¥**ï¼ˆä¼˜å…ˆçº§æ’åº+æ—¶é—´èŠ‚ç‚¹ï¼‰
   - è€ƒè™‘å®ä¹ å‘¨æœŸï¼ˆæš‘æœŸ/å¯’å‡/é•¿æœŸï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- çœŸå®å¯æŸ¥çš„å®ä¹ å²—ä½ä¿¡æ¯
- æ¯æ¡ç»å†åŒ…å«å…·ä½“æ•°å­—
- çªå‡ºå®ä¹ ç”Ÿä¼˜åŠ¿ï¼šå­¦ä¹ å¿«ã€æœ‰æ¿€æƒ…ã€æˆæœ¬ä½
- æ€»å­—æ•°600-800å­—""",
            },

            "interview_coach": {
                "name": "é¢è¯•è¾…å¯¼ä¸“å®¶",
                "prompt": """ä½ æ˜¯ICFè®¤è¯é¢è¯•æ•™ç»ƒï¼Œ10å¹´ç»éªŒï¼Œä¸“æ³¨å®ä¹ ç”Ÿé¢è¯•è¾…å¯¼ã€‚

ä»»åŠ¡ï¼šæä¾›å®Œæ•´çš„å®ä¹ é¢è¯•å‡†å¤‡æ–¹æ¡ˆ

è¾“å‡ºå†…å®¹ï¼š
1. **é«˜é¢‘é—®é¢˜**ï¼ˆ5-8ä¸ªé—®é¢˜+STARå›ç­”æ¨¡æ¿ï¼‰
   - ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå®ä¹ ï¼Ÿ
   - ä½ æœ€å¤§çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
   - é‡åˆ°å›°éš¾å¦‚ä½•è§£å†³ï¼Ÿ
   - å¯¹å…¬å¸/å²—ä½çš„äº†è§£ï¼Ÿ
   - èŒä¸šè§„åˆ’æ˜¯ä»€ä¹ˆï¼Ÿ
2. **æ¨¡æ‹Ÿé¢è¯•**ï¼ˆ3ä¸ªè¿½é—®+è¯„åˆ†æ ‡å‡†ï¼‰
   - é’ˆå¯¹å®ä¹ ç”Ÿçš„å¸¸è§é—®é¢˜
3. **åé—®é—®é¢˜**ï¼ˆ3ä¸ªé«˜è´¨é‡é—®é¢˜ï¼‰
   - å®ä¹ ç”Ÿè½¬æ­£æœºä¼š
   - å¯¼å¸ˆåˆ¶åº¦
   - å­¦ä¹ æˆé•¿æœºä¼š
4. **è–ªèµ„è°ˆåˆ¤**ï¼ˆå®ä¹ ç”Ÿè–ªèµ„èŒƒå›´+è°ˆåˆ¤æŠ€å·§ï¼‰
5. **æ³¨æ„äº‹é¡¹**ï¼ˆç€è£…/æ—¶é—´/ç¤¼ä»ªï¼Œå®ä¹ ç”Ÿç‰¹åˆ«æ³¨æ„ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- æä¾›å¯ç›´æ¥ä½¿ç”¨çš„è¯æœ¯
- åŒ…å«å…·ä½“æ¡ˆä¾‹
- å¼ºè°ƒå­¦ä¹ æ€åº¦å’Œæˆé•¿æ„æ„¿
- æ€»å­—æ•°500-700å­—""",
            },

            "quality_auditor": {
                "name": "è´¨é‡å®¡æ ¸å®˜",
                "prompt": """ä½ æ˜¯ä¸¥æ ¼çš„è´¨é‡å®¡æ ¸ä¸“å®¶ï¼Œ8å¹´ç»éªŒã€‚

ä»»åŠ¡ï¼šå®¡æ ¸å‰é¢æ‰€æœ‰AIçš„è¾“å‡ºï¼Œç»™å‡ºæ”¹è¿›å»ºè®®

å®¡æ ¸ç»´åº¦ï¼š
1. **å†…å®¹è´¨é‡**ï¼ˆ0-100åˆ†+å…·ä½“é—®é¢˜ï¼‰
2. **ATSå‹å¥½åº¦**ï¼ˆ0-100åˆ†+ä¼˜åŒ–å»ºè®®ï¼‰
3. **é€»è¾‘ä¸€è‡´æ€§**ï¼ˆæ—¶é—´/èŒçº§/è–ªèµ„æ£€æŸ¥ï¼‰
4. **å¿…é¡»ä¿®æ”¹çš„3ä¸ªé—®é¢˜**ï¼ˆä¼˜å…ˆçº§æ’åºï¼‰
5. **ç»¼åˆè¯„ä¼°**ï¼ˆé€šè¿‡ç‡é¢„æµ‹0-100%ï¼‰

è¾“å‡ºè¦æ±‚ï¼š
- æ¯ä¸ªé—®é¢˜ç»™å‡ºå…·ä½“æ”¹è¿›æ–¹æ¡ˆ
- è¯„åˆ†å¿…é¡»æœ‰ä¾æ®
- æ€»å­—æ•°400-500å­—""",
            }
        }

    def _ai_think(self, role: str, context: str, show_progress: bool = True) -> str:
        """AIæ€è€ƒ - ä½¿ç”¨æ¨ç†æ¨¡å‹"""
        agent = self.agents[role]

        if show_progress:
            print(f"\nğŸ¤– {agent['name']} æ­£åœ¨æ·±åº¦æ€è€ƒ...")

        try:
            import random
            max_retries = 3
            retry_delay = 3

            for attempt in range(max_retries):
                try:
                    # æ¯æ¬¡é‡è¯•é‡æ–°è·å– clientï¼ˆè½®æ¢ Keyï¼‰
                    if attempt > 0:
                        self.llm_client = get_sync_llm_client()
                        settings = get_llm_settings()
                        self.reasoning_model = settings["reasoning_model"]
                        if show_progress:
                            print(f"   â†» é‡è¯• {attempt + 1}/{max_retries}...")

                    response = self.llm_client.chat.completions.create(
                        model=self.reasoning_model,
                        messages=[
                            {"role": "system", "content": agent['prompt']},
                            {"role": "user", "content": context}
                        ],
                        temperature=0.7
                    )

                    message = response.choices[0].message
                    output = message.content or ""

                    if show_progress:
                        print(f"   âœ“ {agent['name']} å®Œæˆ")

                    return output.strip()

                except Exception as e:
                    error_msg = str(e)
                    if "governor" in error_msg.lower() or "rate" in error_msg.lower() or "429" in error_msg:
                        if attempt < max_retries - 1:
                            if show_progress:
                                print(f"   âš  é™æµï¼Œ{retry_delay}ç§’åé‡è¯•...")
                            time.sleep(retry_delay)
                            retry_delay += 2
                            continue
                    raise

            return f"âŒ {agent['name']} å¤„ç†å¤±è´¥ï¼šæ‰€æœ‰API Keyéƒ½è¾¾åˆ°é™æµ"

        except Exception as e:
            return f"âŒ {agent['name']} å¤„ç†å¤±è´¥: {str(e)}"

    def process_resume(self, resume_text: str) -> Dict[str, Any]:
        """å¤„ç†ç®€å† - 4ä¸ªAgenté¡ºåºæ‰§è¡Œ"""

        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹AIæ±‚èŒåˆ†ææµç¨‹ï¼ˆä½¿ç”¨æ¨ç†æ¨¡å‹ï¼‰")
        print("="*60)

        start_time = time.time()

        # Agent 1: èŒä¸šåˆ†æ
        print("\nã€é˜¶æ®µ1/4ã€‘èŒä¸šåˆ†æ")
        career_analysis = self._ai_think(
            "career_analyst",
            f"è¯·åˆ†æä»¥ä¸‹ç®€å†ï¼š\n\n{resume_text}"
        )

        # Agent 2: å²—ä½åŒ¹é… + ç®€å†ä¼˜åŒ–
        print("\nã€é˜¶æ®µ2/4ã€‘å²—ä½åŒ¹é…ä¸ç®€å†ä¼˜åŒ–")
        job_and_resume = self._ai_think(
            "job_matcher",
            f"ç®€å†ï¼š\n{resume_text}\n\nèŒä¸šåˆ†æï¼š\n{career_analysis}"
        )

        # Agent 3: é¢è¯•è¾…å¯¼
        print("\nã€é˜¶æ®µ3/4ã€‘é¢è¯•å‡†å¤‡")
        interview_prep = self._ai_think(
            "interview_coach",
            f"ç®€å†ï¼š\n{resume_text}\n\nèŒä¸šåˆ†æï¼š\n{career_analysis}\n\nå²—ä½åŒ¹é…ï¼š\n{job_and_resume}"
        )

        # Agent 4: è´¨é‡å®¡æ ¸
        print("\nã€é˜¶æ®µ4/4ã€‘è´¨é‡å®¡æ ¸")
        quality_audit = self._ai_think(
            "quality_auditor",
            f"èŒä¸šåˆ†æï¼š\n{career_analysis}\n\nå²—ä½åŒ¹é…ï¼š\n{job_and_resume}\n\né¢è¯•å‡†å¤‡ï¼š\n{interview_prep}"
        )

        elapsed = time.time() - start_time

        print("\n" + "="*60)
        print(f"âœ… åˆ†æå®Œæˆï¼æ€»è€—æ—¶: {elapsed:.1f}ç§’")
        print("="*60)

        return {
            "career_analysis": career_analysis,
            "job_recommendations": job_and_resume,
            "resume_optimization": job_and_resume,  # åŒ…å«åœ¨å²—ä½åŒ¹é…ä¸­
            "interview_preparation": interview_prep,
            "mock_interview": interview_prep,  # åŒ…å«åœ¨é¢è¯•å‡†å¤‡ä¸­
            "skill_gap_analysis": quality_audit,  # è´¨é‡å®¡æ ¸åŒ…å«æŠ€èƒ½åˆ†æ
            "quality_audit": quality_audit
        }
