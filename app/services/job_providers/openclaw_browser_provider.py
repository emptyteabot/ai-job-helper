from __future__ import annotations

import json
import os
import subprocess
import time
import shutil
import re
import hashlib
from dataclasses import dataclass
from typing import Any, Dict, List, Optional, Tuple
from urllib.parse import quote

from .base import JobProvider, JobSearchParams


class _OpenClawError(RuntimeError):
    pass


@dataclass
class _CmdResult:
    code: int
    stdout: str
    stderr: str


def _run(cmd: List[str], timeout_s: int = 60) -> _CmdResult:
    # On Windows, `openclaw` is typically installed as a `.cmd` shim.
    # Resolve the actual executable to keep argument boundaries intact.
    exe = shutil.which(cmd[0]) or cmd[0]
    p = subprocess.run([exe, *cmd[1:]], capture_output=True, text=True, timeout=timeout_s, shell=False)
    return _CmdResult(p.returncode, p.stdout or "", p.stderr or "")


def _extract_json(text: str) -> Any:
    # OpenClaw prints plugin logs + warnings around the JSON output even with --json.
    # We strip ANSI codes and then use JSONDecoder.raw_decode to find the first
    # valid JSON value in the stream.
    s = (text or "").strip()
    if not s:
        raise _OpenClawError("OpenClaw æ²¡æœ‰è¾“å‡ºã€‚")

    # Strip ANSI escape sequences.
    s = re.sub(r"\x1b\[[0-9;]*m", "", s)

    dec = json.JSONDecoder()
    for i, ch in enumerate(s):
        if ch not in "{[":
            continue
        try:
            obj, _ = dec.raw_decode(s[i:])
            return obj
        except json.JSONDecodeError:
            continue

    raise _OpenClawError("æ— æ³•ä» OpenClaw è¾“å‡ºä¸­è§£æ JSONã€‚")


class OpenClawBrowserProvider(JobProvider):
    """
    Real-time job link scanning using the local OpenClaw dedicated browser.

    This relies on a *human-attached* tab via the OpenClaw Chrome extension relay.
    Workflow:
      1) `openclaw browser start`
      2) Open any tab and click the OpenClaw extension icon to attach
      3) Then call `/api/jobs/search` with JOB_DATA_PROVIDER=openclaw

    This provider only returns job URLs for manual apply (no auto-submit).
    """

    name = "openclaw"

    def __init__(self, browser_profile: Optional[str] = None, timeout_s: int = 90):
        self.browser_profile = (browser_profile or os.getenv("OPENCLAW_BROWSER_PROFILE", "")).strip() or "chrome"
        self.timeout_s = timeout_s
        self._cache: Dict[str, Dict[str, Any]] = {}

    def _oc(self, *args: str, json_out: bool = False, timeout_s: Optional[int] = None) -> _CmdResult:
        cmd = ["openclaw", "browser", "--browser-profile", self.browser_profile]
        if json_out:
            cmd.append("--json")
        cmd.extend(args)
        return _run(cmd, timeout_s=timeout_s or self.timeout_s)

    def _ensure_attached(self) -> None:
        r = self._oc("evaluate", "--fn", "(() => 1)", json_out=True, timeout_s=20)
        if r.code == 0:
            return
        msg = (r.stdout + "\n" + r.stderr).strip()
        if "no tab is connected" in msg.lower():
            raise _OpenClawError(
                "âŒ OpenClaw æµè§ˆå™¨æœªè¿æ¥æ ‡ç­¾é¡µ\n\n"
                "ğŸ“‹ è§£å†³æ­¥éª¤ï¼ˆåªéœ€åšä¸€æ¬¡ï¼‰ï¼š\n"
                "1ï¸âƒ£ æ‰“å¼€å‘½ä»¤è¡Œï¼Œè¿è¡Œ: openclaw browser start\n"
                "2ï¸âƒ£ åœ¨å¼¹å‡ºçš„Chromeä¸­è®¿é—®Bossç›´è˜: https://www.zhipin.com\n"
                "3ï¸âƒ£ ç‚¹å‡»æµè§ˆå™¨å³ä¸Šè§’çš„OpenClawæ‰©å±•å›¾æ ‡ï¼ˆğŸ”§ï¼‰\n"
                "4ï¸âƒ£ ç‚¹å‡» 'Attach' æŒ‰é’®è¿æ¥å½“å‰æ ‡ç­¾é¡µ\n"
                "5ï¸âƒ£ è¿”å›æœ¬é¡µé¢ï¼Œé‡æ–°ç‚¹å‡»æœç´¢\n\n"
                "ğŸ’¡ æç¤ºï¼šè¿æ¥ä¸€æ¬¡åï¼Œåªè¦ä¸å…³é—­æµè§ˆå™¨å°±ä¸€ç›´æœ‰æ•ˆ"
            )
        if "command not found" in msg.lower() or "not recognized" in msg.lower():
            raise _OpenClawError(
                "âŒ OpenClaw æœªå®‰è£…\n\n"
                "ğŸ“¦ å®‰è£…æ­¥éª¤ï¼š\n"
                "1ï¸âƒ£ å®‰è£…PythonåŒ…: pip install openclaw\n"
                "2ï¸âƒ£ å®‰è£…Chromeæ‰©å±•: openclaw browser install-extension\n"
                "3ï¸âƒ£ é‡å¯æµè§ˆå™¨\n"
                "4ï¸âƒ£ è¿”å›æœ¬é¡µé¢é‡è¯•\n\n"
                "ğŸ“– è¯¦ç»†æ–‡æ¡£: docs/howto/OPENCLAW_BOSS_MVP.md"
            )
        raise _OpenClawError(f"âŒ OpenClaw é”™è¯¯: {msg[:500]}\n\nè¯·æ£€æŸ¥OpenClawæ˜¯å¦æ­£ç¡®å®‰è£…å’Œé…ç½®")

    def _navigate_and_collect(self, url: str, want_hosts: List[str], limit: int) -> List[Tuple[str, str]]:
        self._ensure_attached()

        r = self._oc("navigate", url, timeout_s=60)
        if r.code != 0:
            raise _OpenClawError(f"å¯¼èˆªå¤±è´¥: {(r.stdout + r.stderr)[:300]}")

        # Let SPA settle a bit.
        self._oc("wait", "--load", "domcontentloaded", "--timeout-ms", "20000", timeout_s=30)
        self._oc("wait", "--time", "1200", timeout_s=10)

        # Pull anchors.
        js = (
            "() => Array.from(document.querySelectorAll('a[href]')).map(a => ({"
            "href: a.href, text: (a.innerText || a.textContent || '').trim()"
            "})).filter(x => x.href && x.text && x.text.length >= 2).slice(0, 800)"
        )
        r2 = self._oc("evaluate", "--fn", js, json_out=True, timeout_s=30)
        if r2.code != 0:
            raise _OpenClawError(f"è¯»å–é¡µé¢é“¾æ¥å¤±è´¥: {(r2.stdout + r2.stderr)[:300]}")

        data = _extract_json(r2.stdout + "\n" + r2.stderr)
        # OpenClaw returns {"result": ...}. Some commands may return {"value": ...}.
        items = (data.get("result") or data.get("value")) if isinstance(data, dict) else data
        if not isinstance(items, list):
            return []

        out: List[Tuple[str, str]] = []
        seen: set[str] = set()
        for it in items:
            if len(out) >= limit:
                break
            if not isinstance(it, dict):
                continue
            href = str(it.get("href", "")).strip()
            title = str(it.get("text", "")).strip()
            if not href or not title:
                continue
            if href in seen:
                continue
            seen.add(href)
            if want_hosts and not any(h in href for h in want_hosts):
                continue
            # Platform-specific job link filters (reduce navigation/header noise).
            # Boss: only keep job detail links.
            if any("zhipin.com" in h for h in want_hosts):
                if "/job_detail/" not in href:
                    continue
            out.append((title, href))
        return out[:limit]

    def _build_urls(self, params: JobSearchParams) -> List[Tuple[str, str, List[str]]]:
        keywords = " ".join([k for k in (params.keywords or []) if k]).strip() or "æ‹›è˜"
        location = (params.location or "").strip()
        q = quote(f"{keywords} {location}".strip())

        # Default to Boss only for MVP. You can expand via env:
        # OPENCLAW_JOB_SITES=boss,liepin,zhaopin,51job
        sites = (os.getenv("OPENCLAW_JOB_SITES", "") or "boss").strip().lower()
        enabled = {s.strip() for s in sites.split(",") if s.strip()}

        urls: List[Tuple[str, str, List[str]]] = []
        if "boss" in enabled or "zhipin" in enabled:
            urls.append(("Bossç›´è˜", f"https://www.zhipin.com/web/geek/job?query={q}", ["zhipin.com"]))
        if "liepin" in enabled:
            urls.append(("çŒè˜", f"https://www.liepin.com/zhaopin/?key={q}", ["liepin.com"]))
        if "zhaopin" in enabled:
            urls.append(("æ™ºè”æ‹›è˜", f"https://sou.zhaopin.com/?kw={q}", ["zhaopin.com"]))
        if "51job" in enabled or "qcwy" in enabled:
            urls.append(("å‰ç¨‹æ— å¿§", f"https://search.51job.com/list/000000,000000,0000,00,9,99,{q},2,1.html", ["51job.com"]))

        return urls or [("Bossç›´è˜", f"https://www.zhipin.com/web/geek/job?query={q}", ["zhipin.com"])]

    def search_jobs(self, params: JobSearchParams, progress_callback=None) -> List[Dict[str, Any]]:
        # Always local-only.
        urls = self._build_urls(params)
        limit = max(1, min(int(params.limit or 50), 50))

        results: List[Dict[str, Any]] = []
        per_site = max(3, min(15, limit // max(1, len(urls))))

        total_sites = max(1, len(urls))
        for idx, (platform, url, hosts) in enumerate(urls):
            if progress_callback:
                try:
                    progress_callback(
                        f"æ‰“å¼€ {platform} æœç´¢é¡µå¹¶æŠ“å–é“¾æ¥...",
                        int((idx / total_sites) * 100),
                    )
                except Exception:
                    pass
            try:
                pairs = self._navigate_and_collect(url, hosts, per_site)
            except _OpenClawError:
                # Bubble up with actionable error rather than silent fallback.
                raise

            if progress_callback:
                try:
                    progress_callback(
                        f"{platform} æŠ“å–åˆ° {len(pairs)} æ¡é“¾æ¥ï¼Œæ•´ç†ä¸­...",
                        int(((idx + 0.7) / total_sites) * 100),
                    )
                except Exception:
                    pass

            for title, link in pairs:
                job_id = "openclaw_" + hashlib.sha1(link.encode("utf-8", errors="ignore")).hexdigest()[:16]
                job = {
                    "id": job_id,
                    "title": title,
                    "company": "",
                    "location": params.location or "",
                    "salary": "",
                    "description": "",
                    "requirements": [],
                    "platform": platform,
                    "link": link,
                    "updated": "",
                    "provider": self.name,
                }
                self._cache[job_id] = job
                results.append(job)
                if len(results) >= limit:
                    if progress_callback:
                        try:
                            progress_callback("å®Œæˆ", 100)
                        except Exception:
                            pass
                    return results[:limit]

        if progress_callback:
            try:
                progress_callback("å®Œæˆ", 100)
            except Exception:
                pass
        return results[:limit]

    def get_job_detail(self, job_id: str) -> Optional[Dict[str, Any]]:
        return self._cache.get(job_id)

    def health_check(self) -> Dict[str, Any]:
        """
        å¥åº·æ£€æŸ¥ï¼šæ£€æµ‹OpenClawæ˜¯å¦å¯ç”¨
        
        Returns:
            {
                "available": bool,
                "status": str,
                "message": str,
                "browser_connected": bool,
                "tab_attached": bool
            }
        """
        result = {
            "available": False,
            "status": "error",
            "message": "",
            "browser_connected": False,
            "tab_attached": False
        }
        
        # 1. æ£€æŸ¥OpenClawå‘½ä»¤æ˜¯å¦å­˜åœ¨
        if not shutil.which("openclaw"):
            result["message"] = "OpenClawæœªå®‰è£…ã€‚è¯·è¿è¡Œ: pip install openclaw"
            return result
        
        result["browser_connected"] = True
        
        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾é¡µè¿æ¥
        try:
            r = self._oc("evaluate", "--fn", "(() => 1)", json_out=True, timeout_s=10)
            if r.code == 0:
                result["available"] = True
                result["status"] = "ok"
                result["tab_attached"] = True
                result["message"] = "âœ… OpenClawå·²å°±ç»ªï¼Œå¯ä»¥æŠ“å–Bossç›´è˜å²—ä½"
                return result
            
            msg = (r.stdout + "\n" + r.stderr).strip().lower()
            if "no tab is connected" in msg:
                result["message"] = (
                    "âš ï¸ OpenClawå·²å®‰è£…ï¼Œä½†æœªè¿æ¥æ ‡ç­¾é¡µã€‚\n"
                    "è¯·åœ¨Chromeä¸­æ‰“å¼€Bossç›´è˜ï¼Œç‚¹å‡»OpenClawæ‰©å±•å›¾æ ‡å¹¶Attach"
                )
            else:
                result["message"] = f"âš ï¸ OpenClawå¼‚å¸¸: {msg[:200]}"
                
        except Exception as e:
            result["message"] = f"âš ï¸ OpenClawæ£€æŸ¥å¤±è´¥: {str(e)}"
        
        return result
