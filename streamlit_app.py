"""
AIæ±‚èŒåŠ©æ‰‹ - Streamlit å®Œæ•´ç‰ˆ
ç®€å†åˆ†æï¼ˆè€ç‰ˆæœ¬ä»£ç ï¼‰+ è‡ªåŠ¨æŠ•é€’ï¼ˆGitHubé«˜æ˜Ÿé¡¹ç›®ï¼‰
"""
import streamlit as st
import sys
import os
import asyncio
import io

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

st.set_page_config(
    page_title="AIæ±‚èŒåŠ©æ‰‹",
    page_icon="âœ¨",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# å…¨å±€æ ·å¼ - OpenAI æ‰“å­—æœºé£æ ¼
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700;800&family=IBM+Plex+Mono:wght@400;500&display=swap');
:root{--bg:#fff;--text:#131313;--muted:#64646b;--line:#e8e8ec;--soft:#f7f7f9}
*{font-family:'Noto Sans SC',sans-serif;box-sizing:border-box}
#MainMenu,footer,header{visibility:hidden}
.main .block-container{max-width:980px;padding:1.5rem 1rem 3rem}
.top-nav{display:flex;align-items:center;justify-content:space-between;border-bottom:1px solid var(--line);padding:10px 0 16px;margin-bottom:2rem}
.brand{display:flex;align-items:center;gap:9px;font-size:16px;font-weight:800}
.dot{width:8px;height:8px;border-radius:50%;background:#121212;box-shadow:0 0 0 6px rgba(18,18,18,0.08)}
.hero{padding:52px 0 34px}
.pill{display:inline-flex;align-items:center;gap:7px;border:1px solid var(--line);border-radius:999px;background:#fff;color:var(--muted);padding:6px 11px;font:500 12px/1 'IBM Plex Mono',monospace;margin-bottom:16px}
.pill::before{content:"";width:5px;height:5px;border-radius:50%;background:#121212}
.hero h1{font-size:clamp(48px,9vw,84px);font-weight:800;letter-spacing:-1.8px;line-height:1.04;margin-bottom:20px}
.hero-subtitle{color:var(--muted);font-size:24px;line-height:1.75;max-width:780px}
.cursor{display:inline-block;width:8px;height:1em;margin-left:4px;background:#151515;vertical-align:-2px;animation:blink 1s steps(1,end) infinite}
@keyframes blink{0%,48%{opacity:1}49%,100%{opacity:0}}
.panel{border:1px solid var(--line);border-radius:18px;background:#fff;padding:28px;margin-bottom:20px}
.panel h2{font-size:28px;font-weight:700;margin-bottom:16px}
.panel p{font-size:18px;color:var(--muted);line-height:1.6;margin-bottom:20px}
.stButton>button{border:1px solid #121212;background:#121212;color:white;border-radius:12px;padding:16px 28px;font-size:18px;font-weight:700}
.stButton>button:hover{background:#2a2a2a;transform:translateY(-1px)}
.stTextInput>div>div>input,.stTextArea>div>div>textarea{border:1px solid var(--line);border-radius:14px;padding:16px;font-size:18px}
.stTextArea>div>div>textarea{min-height:280px}
.stTabs [data-baseweb="tab-list"]{gap:12px;border-bottom:1px solid var(--line)}
.stTabs [data-baseweb="tab"]{padding:14px 24px;font-size:18px;font-weight:500;color:var(--muted)}
.stTabs [aria-selected="true"]{color:var(--text);border-bottom:2px solid var(--text)}
</style>
""", unsafe_allow_html=True)

# é¡¶éƒ¨å¯¼èˆª
st.markdown('<div class="top-nav"><div class="brand"><div class="dot"></div><span>AIæ±‚èŒåŠ©æ‰‹</span></div></div>', unsafe_allow_html=True)

# Hero åŒºåŸŸ
st.markdown('''
<div class="hero">
    <div class="pill">ä¸“ä¸ºå¤§å­¦ç”Ÿå®ä¹ è®¾è®¡</div>
    <h1>è®© AI å¸®ä½ æ‰¾åˆ°<br>ç†æƒ³å·¥ä½œ<span class="cursor"></span></h1>
    <div class="hero-subtitle">6 ä¸ª AI åä½œåˆ†æç®€å†ï¼Œæ™ºèƒ½æ¨èå²—ä½ï¼Œè‡ªåŠ¨æŠ•é€’åˆ° Bossç›´è˜ã€æ™ºè”æ‹›è˜ã€LinkedIn</div>
</div>
''', unsafe_allow_html=True)

# é…ç½® API Keyï¼ˆç›´æ¥å†™åœ¨ä»£ç é‡Œï¼‰
os.environ['OPENAI_API_KEY'] = 'sk-SnQQxqPPxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxq'
os.environ['OPENAI_BASE_URL'] = 'https://oneapi.gemiaude.com/v1'

# æ–‡ä»¶è§£æå‡½æ•°ï¼ˆè€ç‰ˆæœ¬ä»£ç  - ä¼˜åŒ–ç‰ˆï¼‰
def parse_uploaded_file(uploaded_file):
    """è§£æä¸Šä¼ çš„æ–‡ä»¶ - æ”¯æŒ PDF/Word/å›¾ç‰‡ï¼ˆOCRï¼‰"""
    try:
        file_content = uploaded_file.read()
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        resume_text = ""

        if file_ext == '.txt':
            # æ–‡æœ¬æ–‡ä»¶
            try:
                resume_text = file_content.decode('utf-8')
            except:
                try:
                    resume_text = file_content.decode('gbk', errors='ignore')
                except:
                    resume_text = file_content.decode('latin-1', errors='ignore')

        elif file_ext == '.pdf':
            # PDFæ–‡ä»¶
            try:
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))

                if len(pdf_reader.pages) == 0:
                    st.error("PDF æ–‡ä»¶ä¸ºç©º")
                    return None

                for page_num, page in enumerate(pdf_reader.pages):
                    text = page.extract_text()
                    if text:
                        resume_text += text + "\n"

                if not resume_text.strip():
                    st.warning("PDF å¯èƒ½æ˜¯æ‰«æä»¶ï¼Œå°è¯•ä½¿ç”¨å›¾ç‰‡ä¸Šä¼ æ–¹å¼")
                    return None

            except Exception as e:
                st.error(f"PDF è§£æå¤±è´¥: {str(e)}")
                st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœæ˜¯æ‰«æç‰ˆ PDFï¼Œè¯·è½¬æ¢ä¸ºå›¾ç‰‡åä¸Šä¼ ")
                return None

        elif file_ext in ['.docx', '.doc']:
            # Wordæ–‡ä»¶
            try:
                from docx import Document
                doc = Document(io.BytesIO(file_content))

                # æå–æ®µè½æ–‡æœ¬
                for paragraph in doc.paragraphs:
                    if paragraph.text.strip():
                        resume_text += paragraph.text + "\n"

                # æå–è¡¨æ ¼æ–‡æœ¬
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            if cell.text.strip():
                                resume_text += cell.text + " "
                        resume_text += "\n"

                if not resume_text.strip():
                    st.error("Word æ–‡æ¡£ä¸ºç©ºæˆ–æ— æ³•æå–æ–‡å­—")
                    return None

            except Exception as e:
                st.error(f"Word æ–‡æ¡£è§£æå¤±è´¥: {str(e)}")
                st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿æ–‡ä»¶æœªæŸåï¼Œæˆ–å°è¯•å¦å­˜ä¸º .docx æ ¼å¼")
                return None

        elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:
            # å›¾ç‰‡æ–‡ä»¶ - ä½¿ç”¨OCR
            try:
                from PIL import Image
                import pytesseract

                # æ‰“å¼€å›¾ç‰‡
                image = Image.open(io.BytesIO(file_content))

                # æ˜¾ç¤ºå›¾ç‰‡é¢„è§ˆ
                st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)

                # OCRè¯†åˆ«ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
                with st.spinner("ğŸ” æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—..."):
                    resume_text = pytesseract.image_to_string(image, lang='chi_sim+eng')

                if not resume_text.strip():
                    st.error("å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œæœªèƒ½æå–åˆ°æ–‡å­—")
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å›¾ç‰‡æ¸…æ™°ã€æ–‡å­—å¯è¯»ï¼Œæˆ–å°è¯•è°ƒæ•´å›¾ç‰‡äº®åº¦å’Œå¯¹æ¯”åº¦")
                    return None

            except ImportError:
                st.error("âŒ å›¾ç‰‡ OCR åŠŸèƒ½æœªå®‰è£…")
                st.info("""
                **å®‰è£…æ–¹æ³•ï¼š**

                1. å®‰è£… pytesseractï¼š
                ```bash
                pip install pytesseract
                ```

                2. å®‰è£… Tesseract OCR å¼•æ“ï¼š
                - Windows: https://github.com/UB-Mannheim/tesseract/wiki
                - Mac: `brew install tesseract`
                - Linux: `sudo apt-get install tesseract-ocr`

                æˆ–è€…ä½¿ç”¨æ–‡æœ¬è¾“å…¥æ–¹å¼
                """)
                return None
            except Exception as e:
                st.error(f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}")
                st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å·²å®‰è£… Tesseract OCR å¼•æ“")
                return None

        else:
            st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            return None

        # æ£€æŸ¥æå–çš„æ–‡æœ¬é•¿åº¦
        if resume_text and len(resume_text.strip()) < 50:
            st.warning("âš ï¸ æå–çš„æ–‡å­—å†…å®¹è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æè´¨é‡")

        return resume_text.strip() if resume_text else None

    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")
        return None

# å¼‚æ­¥å‡½æ•°åŒ…è£…å™¨
def run_async(coro):
    """è¿è¡Œå¼‚æ­¥å‡½æ•°çš„åŒæ­¥åŒ…è£…å™¨"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(coro)
        loop.close()
        return result
    except Exception as e:
        st.error(f"æ‰§è¡Œå‡ºé”™: {str(e)}")
        return None

# åˆå§‹åŒ– session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

# æ ‡ç­¾é¡µ
tab1, tab2 = st.tabs(["ğŸ“„ ç®€å†åˆ†æ", "ğŸš€ è‡ªåŠ¨æŠ•é€’"])

with tab1:
    st.markdown('<div class="panel">', unsafe_allow_html=True)
    st.markdown("## ğŸ“„ AI ç®€å†åˆ†æ")

    col1, col2 = st.columns([2, 1])

    with col1:
        method = st.radio("é€‰æ‹©è¾“å…¥æ–¹å¼", ["æ–‡æœ¬è¾“å…¥", "ä¸Šä¼ æ–‡ä»¶"], horizontal=True)

        if method == "æ–‡æœ¬è¾“å…¥":
            resume_text = st.text_area(
                "ç²˜è´´ç®€å†å†…å®¹",
                height=280,
                placeholder="è¯·åœ¨æ­¤ç²˜è´´æ‚¨çš„ç®€å†å†…å®¹...\n\næ”¯æŒä¸­è‹±æ–‡ç®€å†",
                help="ç›´æ¥ç²˜è´´ç®€å†æ–‡æœ¬ï¼Œæ”¯æŒä¸­è‹±æ–‡"
            )

            if resume_text and st.button("å¼€å§‹åˆ†æ", type="primary", key="analyze_text"):
                if len(resume_text.strip()) < 50:
                    st.warning("âš ï¸ ç®€å†å†…å®¹è¾ƒå°‘ï¼Œå»ºè®®è‡³å°‘ 50 å­—ä»¥ä¸Š")
                else:
                    with st.spinner("ğŸ”„ AI æ­£åœ¨åˆ†ææ‚¨çš„ç®€å†..."):
                        try:
                            # å¯¼å…¥åˆ†æå¼•æ“
                            from app.core.multi_ai_debate import JobApplicationPipeline

                            # åˆ›å»ºåˆ†æç®¡é“
                            pipeline = JobApplicationPipeline()

                            # æ‰§è¡Œåˆ†æï¼ˆä½¿ç”¨åŒæ­¥åŒ…è£…å™¨ï¼‰
                            results = run_async(pipeline.process_resume(resume_text))

                            if results:
                                # ä¿å­˜ç»“æœåˆ° session state
                                st.session_state.analysis_results = results

                                # æ˜¾ç¤ºç»“æœ
                                st.success("âœ… åˆ†æå®Œæˆï¼")

                                # ä½¿ç”¨æ ‡ç­¾é¡µæ˜¾ç¤ºç»“æœ
                                result_tabs = st.tabs(["ğŸ¯ èŒä¸šåˆ†æ", "ğŸ’¼ å²—ä½æ¨è", "âœï¸ ç®€å†ä¼˜åŒ–", "ğŸ“š é¢è¯•å‡†å¤‡", "ğŸ¤ æ¨¡æ‹Ÿé¢è¯•", "ğŸ“ˆ æŠ€èƒ½åˆ†æ"])

                                with result_tabs[0]:
                                    st.markdown(results.get('career_analysis', 'æš‚æ— æ•°æ®'))

                                with result_tabs[1]:
                                    st.markdown(results.get('job_recommendations', 'æš‚æ— æ•°æ®'))

                                with result_tabs[2]:
                                    st.markdown(results.get('resume_optimization', 'æš‚æ— æ•°æ®'))

                                with result_tabs[3]:
                                    st.markdown(results.get('interview_preparation', 'æš‚æ— æ•°æ®'))

                                with result_tabs[4]:
                                    st.markdown(results.get('mock_interview', 'æš‚æ— æ•°æ®'))

                                with result_tabs[5]:
                                    st.markdown(results.get('skill_gap_analysis', 'æš‚æ— æ•°æ®'))

                        except Exception as e:
                            st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                            st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API é…ç½®")

        else:  # ä¸Šä¼ æ–‡ä»¶
            uploaded_file = st.file_uploader(
                "æ”¯æŒ PDFã€Wordã€å›¾ç‰‡ã€æ–‡æœ¬",
                type=["pdf", "doc", "docx", "png", "jpg", "jpeg", "txt"],
                help="æ”¯æŒ PDFã€Word æ–‡æ¡£ã€å›¾ç‰‡ï¼ˆOCRè¯†åˆ«ï¼‰å’Œæ–‡æœ¬æ–‡ä»¶"
            )

            if uploaded_file:
                st.success(f"âœ“ å·²ä¸Šä¼ : {uploaded_file.name} ({uploaded_file.size / 1024:.1f} KB)")

                if st.button("å¼€å§‹åˆ†æ", type="primary", key="analyze_file"):
                    with st.spinner("ğŸ”„ æ­£åœ¨è§£ææ–‡ä»¶..."):
                        # ä½¿ç”¨è€ç‰ˆæœ¬çš„è§£æä»£ç 
                        resume_text = parse_uploaded_file(uploaded_file)

                    if resume_text:
                        st.success(f"âœ… æ–‡ä»¶è§£ææˆåŠŸï¼Œæå–äº† {len(resume_text)} ä¸ªå­—ç¬¦")

                        # æ˜¾ç¤ºæå–çš„æ–‡æœ¬é¢„è§ˆ
                        with st.expander("ğŸ“„ æŸ¥çœ‹æå–çš„æ–‡æœ¬"):
                            st.text(resume_text[:500] + "..." if len(resume_text) > 500 else resume_text)

                        with st.spinner("ğŸ”„ AI æ­£åœ¨åˆ†ææ‚¨çš„ç®€å†..."):
                            try:
                                # å¯¼å…¥åˆ†æå¼•æ“
                                from app.core.multi_ai_debate import JobApplicationPipeline

                                # åˆ›å»ºåˆ†æç®¡é“
                                pipeline = JobApplicationPipeline()

                                # æ‰§è¡Œåˆ†æ
                                results = run_async(pipeline.process_resume(resume_text))

                                if results:
                                    # ä¿å­˜ç»“æœåˆ° session state
                                    st.session_state.analysis_results = results

                                    # æ˜¾ç¤ºç»“æœ
                                    st.success("âœ… åˆ†æå®Œæˆï¼")

                                    # æ˜¾ç¤ºå„ä¸ªåˆ†æç»“æœ
                                    with st.expander("ğŸ¯ èŒä¸šåˆ†æ", expanded=True):
                                        st.write(results.get('career_analysis', 'æš‚æ— æ•°æ®'))

                                    with st.expander("ğŸ’¼ å²—ä½æ¨è"):
                                        st.write(results.get('job_recommendations', 'æš‚æ— æ•°æ®'))

                                    with st.expander("âœï¸ ç®€å†ä¼˜åŒ–"):
                                        st.write(results.get('resume_optimization', 'æš‚æ— æ•°æ®'))

                                    with st.expander("ğŸ“š é¢è¯•å‡†å¤‡"):
                                        st.write(results.get('interview_preparation', 'æš‚æ— æ•°æ®'))

                                    with st.expander("ğŸ¤ æ¨¡æ‹Ÿé¢è¯•"):
                                        st.write(results.get('mock_interview', 'æš‚æ— æ•°æ®'))

                                    with st.expander("ğŸ“ˆ æŠ€èƒ½åˆ†æ"):
                                        st.write(results.get('skill_gap_analysis', 'æš‚æ— æ•°æ®'))

                            except Exception as e:
                                st.error(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
                                st.info("ğŸ’¡ æç¤ºï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ API é…ç½®")

    with col2:
        st.markdown("""### åˆ†æå†…å®¹
- ğŸ¯ èŒä¸šåˆ†æ
- ğŸ’¼ å²—ä½æ¨è
- âœï¸ ç®€å†ä¼˜åŒ–
- ğŸ“š é¢è¯•å‡†å¤‡
- ğŸ¤ æ¨¡æ‹Ÿé¢è¯•
- ğŸ“ˆ æŠ€èƒ½åˆ†æ

### æ”¯æŒæ ¼å¼
- ğŸ“„ PDF æ–‡æ¡£
- ğŸ“ Word æ–‡æ¡£
- ğŸ–¼ï¸ å›¾ç‰‡ï¼ˆOCRï¼‰
- ğŸ“‹ æ–‡æœ¬æ–‡ä»¶

### ä½¿ç”¨æç¤º
1. æ–‡æœ¬è¾“å…¥æœ€å¿«
2. PDF/Word è‡ªåŠ¨è§£æ
3. å›¾ç‰‡éœ€è¦ OCR è¯†åˆ«
4. å»ºè®®ç®€å† > 50 å­—""")

    st.markdown('</div>', unsafe_allow_html=True)

with tab2:
    st.markdown('<div class="panel">', unsafe_allow_html=True)
    st.markdown("## ğŸš€ è‡ªåŠ¨æŠ•é€’")

    st.info("""
    **åŸºäº GitHub é«˜æ˜Ÿé¡¹ç›®** [GodsScion/Auto_job_applier_linkedIn](https://github.com/GodsScion/Auto_job_applier_linkedIn) (1544â­)

    âœ¨ æ™ºèƒ½åŒ– - AI è‡ªåŠ¨å›ç­”ç”³è¯·è¡¨å•
    âš¡ é«˜æ•ˆç‡ - æ¯å°æ—¶å¯æŠ•é€’ 50+ èŒä½
    ğŸ”’ å®‰å…¨æ€§ - ä½¿ç”¨åæ£€æµ‹æŠ€æœ¯
    ğŸ“Š å¯è¿½è¸ª - å®Œæ•´çš„æŠ•é€’å†å²è®°å½•
    """)

    platforms = st.multiselect(
        "é€‰æ‹©å¹³å°",
        ["LinkedIn (Easy Apply)", "Bossç›´è˜", "æ™ºè”æ‹›è˜"],
        default=["LinkedIn (Easy Apply)"],
        help="LinkedIn åŸºäº GitHub é«˜æ˜Ÿé¡¹ç›®ï¼Œå…¶ä»–å¹³å°å¼€å‘ä¸­"
    )

    if platforms:
        col1, col2 = st.columns(2)

        with col1:
            keywords = st.text_input("æœç´¢å…³é”®è¯", value="Python Developer, Full Stack Engineer", help="å¤šä¸ªå…³é”®è¯ç”¨é€—å·åˆ†éš”")
            locations = st.text_input("å·¥ä½œåœ°ç‚¹", value="Remote, San Francisco, åŒ—äº¬", help="å¤šä¸ªåœ°ç‚¹ç”¨é€—å·åˆ†éš”")

        with col2:
            max_count = st.number_input("æŠ•é€’æ•°é‡", 1, 500, 50, help="å»ºè®®æ¯æ¬¡ 50 ä¸ªä»¥å†…ï¼Œé¿å…è¢«å°å·")
            interval = st.slider("æŠ•é€’é—´éš”ï¼ˆç§’ï¼‰", 3, 30, 5, help="é—´éš”æ—¶é—´è¶Šé•¿è¶Šå®‰å…¨")

        st.markdown("### é«˜çº§é…ç½®")

        col3, col4 = st.columns(2)

        with col3:
            blacklist = st.text_area(
                "å…¬å¸é»‘åå•ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                height=100,
                placeholder="ä¸æƒ³æŠ•é€’çš„å…¬å¸åç§°\næ¯è¡Œä¸€ä¸ª"
            )

        with col4:
            pause_before_submit = st.checkbox("æäº¤å‰æš‚åœå®¡æ ¸", value=False, help="æ¯æ¬¡æäº¤å‰æš‚åœï¼Œäººå·¥å®¡æ ¸")
            easy_apply_only = st.checkbox("ä»… Easy Apply èŒä½", value=True, help="åªæŠ•é€’æ”¯æŒå¿«é€Ÿç”³è¯·çš„èŒä½")

        if st.button("å¼€å§‹æŠ•é€’", type="primary"):
            st.warning("âš ï¸ è‡ªåŠ¨æŠ•é€’åŠŸèƒ½éœ€è¦æœ¬åœ°è¿è¡Œï¼ˆæµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼‰")

            with st.expander("ğŸ“– æœ¬åœ°è¿è¡ŒæŒ‡å—", expanded=True):
                st.markdown("""
                ### æ–¹å¼ 1ï¼šä½¿ç”¨ FastAPI åç«¯ï¼ˆæ¨èï¼‰

                ```bash
                # 1. å®‰è£…ä¾èµ–
                pip install playwright undetected-chromedriver
                playwright install chromium

                # 2. å¯åŠ¨åç«¯
                python web_app.py

                # 3. è®¿é—®è‡ªåŠ¨æŠ•é€’é¢æ¿
                http://localhost:8000/static/auto_apply_panel.html
                ```

                ### æ–¹å¼ 2ï¼šç›´æ¥ä½¿ç”¨ GitHub é«˜æ˜Ÿé¡¹ç›®

                ```bash
                # 1. å…‹éš†é¡¹ç›®
                git clone https://github.com/GodsScion/Auto_job_applier_linkedIn.git
                cd Auto_job_applier_linkedIn

                # 2. å®‰è£…ä¾èµ–
                pip install -r requirements.txt

                # 3. é…ç½® config.yaml
                # å¡«å†™ä½ çš„ LinkedIn è´¦å·å’ŒæŠ•é€’å‚æ•°

                # 4. è¿è¡Œ
                python main.py
                ```

                ### ä¸ºä»€ä¹ˆ Streamlit Cloud ä¸æ”¯æŒï¼Ÿ

                - æµè§ˆå™¨è‡ªåŠ¨åŒ–éœ€è¦ Chromium/Chrome
                - éœ€è¦æŒä¹…åŒ–ä¼šè¯å’Œ Cookie
                - éœ€è¦å›¾å½¢ç•Œé¢ç¯å¢ƒ
                - Streamlit Cloud æ˜¯æ— å¤´ç¯å¢ƒï¼Œä¸æ”¯æŒè¿™äº›åŠŸèƒ½

                ### æ¨èæ¶æ„

                ```
                Streamlit Cloud (å‰ç«¯ UI)
                     â†“ API è°ƒç”¨
                Railway/æœ¬åœ° (åç«¯ + æµè§ˆå™¨è‡ªåŠ¨åŒ–)
                ```

                ### å®‰å…¨æç¤º

                âš ï¸ **é‡è¦ï¼š**
                - ä¸è¦è¿‡åº¦ä½¿ç”¨ï¼Œé¿å…è´¦å·è¢«å°
                - å»ºè®®æ¯å¤©æŠ•é€’ä¸è¶…è¿‡ 100 ä¸ª
                - ä½¿ç”¨é—´éš”æ—¶é—´ 5-10 ç§’
                - å®šæœŸæ›´æ¢ IP åœ°å€
                """)

    st.markdown('</div>', unsafe_allow_html=True)

# é¡µè„š
st.markdown("---")
st.markdown('''
<div style="text-align:center;color:var(--muted);padding:32px 0;font-size:16px">
    <p>ğŸ’¼ ç¥ä½ æ±‚èŒé¡ºåˆ©</p>
    <p>
        <a href="https://github.com/emptyteabot/ai-job-helper" style="color:var(--text);margin:0 16px">GitHub</a>
        <a href="https://github.com/GodsScion/Auto_job_applier_linkedIn" style="color:var(--text);margin:0 16px">é«˜æ˜Ÿé¡¹ç›®</a>
        <a href="https://ai-job-apper-ibpzap2nnajzrnu8mkthuv.streamlit.app" style="color:var(--text);margin:0 16px">åœ¨çº¿ä½“éªŒ</a>
    </p>
</div>
''', unsafe_allow_html=True)
