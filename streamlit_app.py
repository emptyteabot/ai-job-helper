"""
AIæ±‚èŒåŠ©æ‰‹ - Streamlit å®Œæ•´ç‰ˆ
ç®€å†åˆ†æï¼ˆè€ç‰ˆæœ¬ä»£ç ï¼‰+ è‡ªåŠ¨æŠ•é€’ï¼ˆGitHubé«˜æ˜Ÿé¡¹ç›®ï¼‰
"""
import streamlit as st
import sys
import os
import asyncio
import io

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(__file__))

st.set_page_config(
    page_title="AIæ±‚èŒåŠ©æ‰‹",
    page_icon="âœ¨",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# å…¨å±€æ ·å¼ - Gemini æç®€é£æ ¼
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Google+Sans:wght@400;500;700&family=Noto+Sans+SC:wght@400;500;700&display=swap');

:root {
    --gemini-blue: #1a73e8;
    --gemini-blue-hover: #1557b0;
    --text: #1f1f1f;
    --text-light: #5f6368;
    --border: #e8eaed;
    --bg: #ffffff;
    --bg-hover: #f8f9fa;
}

* {
    font-family: 'Google Sans', 'Noto Sans SC', sans-serif;
}

#MainMenu, footer, header {visibility: hidden}

.main .block-container {
    max-width: 900px;
    padding: 1rem 1.5rem 3rem;
}

/* é¡¶éƒ¨ Logo */
.logo {
    font-size: 1.375rem;
    font-weight: 500;
    color: var(--text);
    padding: 1rem 0;
    margin-bottom: 2rem;
}

/* Hero */
.hero {
    margin-bottom: 3rem;
}

.hero h1 {
    font-size: 2.75rem;
    font-weight: 400;
    color: var(--text);
    line-height: 1.3;
    margin-bottom: 0.75rem;
}

.hero p {
    font-size: 1rem;
    color: var(--text-light);
    line-height: 1.5;
}

/* æŒ‰é’® */
.stButton > button {
    background: var(--gemini-blue);
    color: white;
    border: none;
    border-radius: 24px;
    padding: 0.625rem 1.5rem;
    font-size: 0.875rem;
    font-weight: 500;
    transition: background 0.2s;
}

.stButton > button:hover {
    background: var(--gemini-blue-hover);
}

/* è¾“å…¥æ¡† */
.stTextInput > div > div > input,
.stTextArea > div > div > textarea {
    border: 1px solid var(--border);
    border-radius: 8px;
    padding: 0.75rem;
    font-size: 0.875rem;
    transition: border 0.2s;
}

.stTextInput > div > div > input:focus,
.stTextArea > div > div > textarea:focus {
    border-color: var(--gemini-blue);
    outline: none;
}

.stTextArea > div > div > textarea {
    min-height: 180px;
}

/* æ ‡ç­¾é¡µ */
.stTabs [data-baseweb="tab-list"] {
    gap: 0;
    border-bottom: 1px solid var(--border);
}

.stTabs [data-baseweb="tab"] {
    padding: 0.75rem 1rem;
    font-size: 0.875rem;
    font-weight: 500;
    color: var(--text-light);
    border: none;
}

.stTabs [aria-selected="true"] {
    color: var(--gemini-blue);
    border-bottom: 2px solid var(--gemini-blue);
}

/* Radio */
.stRadio > div {
    gap: 1rem;
}

.stRadio label {
    font-size: 0.875rem;
    color: var(--text);
}

/* ä¿¡æ¯æ¡† */
.stAlert {
    border-radius: 8px;
    border: 1px solid var(--border);
    background: var(--bg-hover);
}

/* æ–‡ä»¶ä¸Šä¼  */
.stFileUploader {
    border: 1px dashed var(--border);
    border-radius: 8px;
    padding: 1.5rem;
}

/* ç§»é™¤å¤šä½™è£…é¥° */
.stExpander {
    border: none;
    box-shadow: none;
}
</style>
""", unsafe_allow_html=True)

# Logo
st.markdown('<div class="logo">AI æ±‚èŒåŠ©æ‰‹</div>', unsafe_allow_html=True)

# Hero
st.markdown('''
<div class="hero">
    <h1>è®© AI å¸®ä½ æ‰¾åˆ°ç†æƒ³å·¥ä½œ</h1>
    <p>åˆ†æç®€å†ï¼Œæ¨èå²—ä½ï¼Œè‡ªåŠ¨æŠ•é€’</p>
</div>
''', unsafe_allow_html=True)

# é…ç½® API Keyï¼ˆç›´æ¥å†™åœ¨ä»£ç é‡Œï¼‰
os.environ['OPENAI_API_KEY'] = 'sk-SnQQxqPPxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxqxq'
os.environ['OPENAI_BASE_URL'] = 'https://oneapi.gemiaude.com/v1'

# æ–‡ä»¶è§£æå‡½æ•°ï¼ˆè€ç‰ˆæœ¬ä»£ç  - ä¼˜åŒ–ç‰ˆï¼‰
def parse_uploaded_file(uploaded_file):
    """è§£æä¸Šä¼ çš„æ–‡ä»¶ - æ”¯æŒ PDF/Word/å›¾ç‰‡ï¼ˆOCRï¼‰"""
    try:
        file_content = uploaded_file.read()
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        resume_text = ""

        if file_ext == '.txt':
            # æ–‡æœ¬æ–‡ä»¶
            try:
                resume_text = file_content.decode('utf-8')
            except:
                try:
                    resume_text = file_content.decode('gbk', errors='ignore')
                except:
                    resume_text = file_content.decode('latin-1', errors='ignore')

        elif file_ext == '.pdf':
            # PDFæ–‡ä»¶
            try:
                import PyPDF2
                pdf_reader = PyPDF2.PdfReader(io.BytesIO(file_content))

                if len(pdf_reader.pages) == 0:
                    st.error("PDF æ–‡ä»¶ä¸ºç©º")
                    return None

                for page_num, page in enumerate(pdf_reader.pages):
                    text = page.extract_text()
                    if text:
                        resume_text += text + "\n"

                if not resume_text.strip():
                    st.warning("PDF å¯èƒ½æ˜¯æ‰«æä»¶ï¼Œå°è¯•ä½¿ç”¨å›¾ç‰‡ä¸Šä¼ æ–¹å¼")
                    return None

            except Exception as e:
                st.error(f"PDF è§£æå¤±è´¥: {str(e)}")
                st.info("ğŸ’¡ æç¤ºï¼šå¦‚æœæ˜¯æ‰«æç‰ˆ PDFï¼Œè¯·è½¬æ¢ä¸ºå›¾ç‰‡åä¸Šä¼ ")
                return None

        elif file_ext in ['.docx', '.doc']:
            # Wordæ–‡ä»¶
            try:
                from docx import Document
                doc = Document(io.BytesIO(file_content))

                # æå–æ®µè½æ–‡æœ¬
                for paragraph in doc.paragraphs:
                    if paragraph.text.strip():
                        resume_text += paragraph.text + "\n"

                # æå–è¡¨æ ¼æ–‡æœ¬
                for table in doc.tables:
                    for row in table.rows:
                        for cell in row.cells:
                            if cell.text.strip():
                                resume_text += cell.text + " "
                        resume_text += "\n"

                if not resume_text.strip():
                    st.error("Word æ–‡æ¡£ä¸ºç©ºæˆ–æ— æ³•æå–æ–‡å­—")
                    return None

            except Exception as e:
                st.error(f"Word æ–‡æ¡£è§£æå¤±è´¥: {str(e)}")
                st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿æ–‡ä»¶æœªæŸåï¼Œæˆ–å°è¯•å¦å­˜ä¸º .docx æ ¼å¼")
                return None

        elif file_ext in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:
            # å›¾ç‰‡æ–‡ä»¶ - ä½¿ç”¨OCR
            try:
                from PIL import Image
                import pytesseract

                # æ‰“å¼€å›¾ç‰‡
                image = Image.open(io.BytesIO(file_content))

                # æ˜¾ç¤ºå›¾ç‰‡é¢„è§ˆ
                st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_container_width=True)

                # OCRè¯†åˆ«ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
                with st.spinner("ğŸ” æ­£åœ¨è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—..."):
                    resume_text = pytesseract.image_to_string(image, lang='chi_sim+eng')

                if not resume_text.strip():
                    st.error("å›¾ç‰‡è¯†åˆ«å¤±è´¥ï¼Œæœªèƒ½æå–åˆ°æ–‡å­—")
                    st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å›¾ç‰‡æ¸…æ™°ã€æ–‡å­—å¯è¯»ï¼Œæˆ–å°è¯•è°ƒæ•´å›¾ç‰‡äº®åº¦å’Œå¯¹æ¯”åº¦")
                    return None

            except ImportError:
                st.error("âŒ å›¾ç‰‡ OCR åŠŸèƒ½æœªå®‰è£…")
                st.info("""
                **å®‰è£…æ–¹æ³•ï¼š**

                1. å®‰è£… pytesseractï¼š
                ```bash
                pip install pytesseract
                ```

                2. å®‰è£… Tesseract OCR å¼•æ“ï¼š
                - Windows: https://github.com/UB-Mannheim/tesseract/wiki
                - Mac: `brew install tesseract`
                - Linux: `sudo apt-get install tesseract-ocr`

                æˆ–è€…ä½¿ç”¨æ–‡æœ¬è¾“å…¥æ–¹å¼
                """)
                return None
            except Exception as e:
                st.error(f"å›¾ç‰‡è¯†åˆ«å¤±è´¥: {str(e)}")
                st.info("ğŸ’¡ æç¤ºï¼šè¯·ç¡®ä¿å·²å®‰è£… Tesseract OCR å¼•æ“")
                return None

        else:
            st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
            return None

        # æ£€æŸ¥æå–çš„æ–‡æœ¬é•¿åº¦
        if resume_text and len(resume_text.strip()) < 50:
            st.warning("âš ï¸ æå–çš„æ–‡å­—å†…å®¹è¾ƒå°‘ï¼Œå¯èƒ½å½±å“åˆ†æè´¨é‡")

        return resume_text.strip() if resume_text else None

    except Exception as e:
        st.error(f"æ–‡ä»¶è§£æå¤±è´¥: {str(e)}")
        return None

# å¼‚æ­¥å‡½æ•°åŒ…è£…å™¨
def run_async(coro):
    """è¿è¡Œå¼‚æ­¥å‡½æ•°çš„åŒæ­¥åŒ…è£…å™¨"""
    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(coro)
        loop.close()
        return result
    except Exception as e:
        st.error(f"æ‰§è¡Œå‡ºé”™: {str(e)}")
        return None

# åˆå§‹åŒ– session state
if 'analysis_results' not in st.session_state:
    st.session_state.analysis_results = None

# æ ‡ç­¾é¡µ
tab1, tab2 = st.tabs(["ç®€å†åˆ†æ", "è‡ªåŠ¨æŠ•é€’"])

with tab1:
    st.markdown("### ç®€å†åˆ†æ")

    method = st.radio("", ["æ–‡æœ¬è¾“å…¥", "ä¸Šä¼ æ–‡ä»¶"], horizontal=True, label_visibility="collapsed")

    if method == "æ–‡æœ¬è¾“å…¥":
        resume_text = st.text_area(
            "",
            height=180,
            placeholder="ç²˜è´´ä½ çš„ç®€å†å†…å®¹...",
            label_visibility="collapsed"
        )

        if resume_text and st.button("åˆ†æ", type="primary", key="analyze_text"):
            if len(resume_text.strip()) < 50:
                st.warning("ç®€å†å†…å®¹è¾ƒå°‘ï¼Œå»ºè®®è‡³å°‘ 50 å­—ä»¥ä¸Š")
            else:
                with st.spinner("åˆ†æä¸­..."):
                    try:
                        # å¯¼å…¥åˆ†æå¼•æ“
                        from app.core.multi_ai_debate import JobApplicationPipeline

                        # åˆ›å»ºåˆ†æç®¡é“
                        pipeline = JobApplicationPipeline()

                        # æ‰§è¡Œåˆ†æï¼ˆä½¿ç”¨åŒæ­¥åŒ…è£…å™¨ï¼‰
                        results = run_async(pipeline.process_resume(resume_text))

                        if results:
                            # ä¿å­˜ç»“æœåˆ° session state
                            st.session_state.analysis_results = results

                            # æ˜¾ç¤ºç»“æœ
                            st.success("å®Œæˆ")

                            # ä½¿ç”¨æ ‡ç­¾é¡µæ˜¾ç¤ºç»“æœ
                            result_tabs = st.tabs(["èŒä¸šåˆ†æ", "å²—ä½æ¨è", "ç®€å†ä¼˜åŒ–", "é¢è¯•å‡†å¤‡", "æ¨¡æ‹Ÿé¢è¯•", "æŠ€èƒ½åˆ†æ"])

                                with result_tabs[0]:
                                    st.markdown(results.get('career_analysis', 'æš‚æ— æ•°æ®'))

                                with result_tabs[1]:
                                    st.markdown(results.get('job_recommendations', 'æš‚æ— æ•°æ®'))

                                with result_tabs[2]:
                                    st.markdown(results.get('resume_optimization', 'æš‚æ— æ•°æ®'))

                                with result_tabs[3]:
                                    st.markdown(results.get('interview_preparation', 'æš‚æ— æ•°æ®'))

                                with result_tabs[4]:
                                    st.markdown(results.get('mock_interview', 'æš‚æ— æ•°æ®'))

                                with result_tabs[5]:
                                    st.markdown(results.get('skill_gap_analysis', 'æš‚æ— æ•°æ®'))

                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")

    else:  # ä¸Šä¼ æ–‡ä»¶
        uploaded_file = st.file_uploader(
            "",
            type=["pdf", "doc", "docx", "png", "jpg", "jpeg", "txt"],
            label_visibility="collapsed"
        )

        if uploaded_file:
            if st.button("åˆ†æ", type="primary", key="analyze_file"):
                with st.spinner("è§£æä¸­..."):
                    # ä½¿ç”¨è€ç‰ˆæœ¬çš„è§£æä»£ç 
                    resume_text = parse_uploaded_file(uploaded_file)

                if resume_text:
                    with st.spinner("åˆ†æä¸­..."):
                        try:
                            # å¯¼å…¥åˆ†æå¼•æ“
                            from app.core.multi_ai_debate import JobApplicationPipeline

                            # åˆ›å»ºåˆ†æç®¡é“
                            pipeline = JobApplicationPipeline()

                            # æ‰§è¡Œåˆ†æ
                            results = run_async(pipeline.process_resume(resume_text))

                            if results:
                                # ä¿å­˜ç»“æœåˆ° session state
                                st.session_state.analysis_results = results

                                # æ˜¾ç¤ºç»“æœ
                                st.success("å®Œæˆ")

                                # æ˜¾ç¤ºå„ä¸ªåˆ†æç»“æœ
                                with st.expander("èŒä¸šåˆ†æ", expanded=True):
                                    st.write(results.get('career_analysis', 'æš‚æ— æ•°æ®'))

                                with st.expander("å²—ä½æ¨è"):
                                    st.write(results.get('job_recommendations', 'æš‚æ— æ•°æ®'))

                                with st.expander("ç®€å†ä¼˜åŒ–"):
                                    st.write(results.get('resume_optimization', 'æš‚æ— æ•°æ®'))

                                with st.expander("é¢è¯•å‡†å¤‡"):
                                    st.write(results.get('interview_preparation', 'æš‚æ— æ•°æ®'))

                                with st.expander("æ¨¡æ‹Ÿé¢è¯•"):
                                    st.write(results.get('mock_interview', 'æš‚æ— æ•°æ®'))

                                with st.expander("æŠ€èƒ½åˆ†æ"):
                                    st.write(results.get('skill_gap_analysis', 'æš‚æ— æ•°æ®'))

                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {str(e)}")

with tab2:
    st.markdown("### è‡ªåŠ¨æŠ•é€’")

    st.info("åŸºäº GitHub é«˜æ˜Ÿé¡¹ç›® [GodsScion/Auto_job_applier_linkedIn](https://github.com/GodsScion/Auto_job_applier_linkedIn)")

    platforms = st.multiselect(
        "å¹³å°",
        ["LinkedIn (Easy Apply)", "Bossç›´è˜", "æ™ºè”æ‹›è˜"],
        default=["LinkedIn (Easy Apply)"]
    )

    if platforms:
        col1, col2 = st.columns(2)

        with col1:
            keywords = st.text_input("å…³é”®è¯", value="Python Developer")
            locations = st.text_input("åœ°ç‚¹", value="Remote")

        with col2:
            max_count = st.number_input("æ•°é‡", 1, 500, 50)
            interval = st.slider("é—´éš”ï¼ˆç§’ï¼‰", 3, 30, 5)

        if st.button("å¼€å§‹æŠ•é€’", type="primary"):
            st.warning("éœ€è¦æœ¬åœ°è¿è¡Œ")

            with st.expander("æœ¬åœ°è¿è¡ŒæŒ‡å—"):
                st.markdown("""
                ```bash
                # å…‹éš†é¡¹ç›®
                git clone https://github.com/GodsScion/Auto_job_applier_linkedIn.git
                cd Auto_job_applier_linkedIn

                # å®‰è£…ä¾èµ–
                pip install -r requirements.txt

                # é…ç½® config.yaml
                # å¡«å†™ä½ çš„ LinkedIn è´¦å·å’ŒæŠ•é€’å‚æ•°

                # è¿è¡Œ
                python main.py
                ```
                """)

# é¡µè„š
st.markdown('''
<div style="text-align:center;color:var(--text-light);padding:2rem 0;font-size:0.75rem;border-top:1px solid var(--border);margin-top:3rem">
    <a href="https://github.com/emptyteabot/ai-job-helper" style="color:var(--text-light);margin:0 1rem;text-decoration:none">GitHub</a>
    <a href="https://github.com/GodsScion/Auto_job_applier_linkedIn" style="color:var(--text-light);margin:0 1rem;text-decoration:none">é«˜æ˜Ÿé¡¹ç›®</a>
</div>
''', unsafe_allow_html=True)
